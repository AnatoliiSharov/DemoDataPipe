 Network kafka_kraft_my_network  Creating
 Network kafka_kraft_my_network  Created
 Container kafka1  Creating
 Container kafka1  Created
 Container schema-registry  Creating
 Container kafka_kraft-kafka-init-topics-1  Creating
 Container schema-registry  Created
 Container kafka-ui  Creating
 Container kafka_kraft-kafka-init-topics-1  Created
 Container kafka-ui  Created
Attaching to kafka-ui, kafka1, kafka_kraft-kafka-init-topics-1, schema-registry
schema-registry                  | ===> User
schema-registry                  | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
schema-registry                  | ===> Configuring ...
kafka1                           | ===> User
kafka1                           | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
kafka1                           | ===> Configuring ...
kafka1                           | Running in KRaft mode...
kafka-ui                         | 11:55:09,295 |-INFO in ch.qos.logback.classic.LoggerContext[default] - This is logback-classic version 1.4.7
kafka-ui                         | 11:55:10,309 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
kafka-ui                         | 11:55:10,322 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml]
kafka-ui                         | 11:55:10,391 |-INFO in ch.qos.logback.classic.BasicConfigurator@433d61fb - Setting up default configuration.
kafka-ui                         | 11:55:16,646 |-INFO in ch.qos.logback.core.joran.spi.ConfigurationWatchList@5c909414 - URL [jar:file:/kafka-ui-api.jar!/BOOT-INF/classes!/logback-spring.xml] is not of type file
kafka-ui                         | 11:55:17,317 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - Processing appender named [STDOUT]
kafka-ui                         | 11:55:17,317 |-INFO in ch.qos.logback.core.model.processor.AppenderModelHandler - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender]
kafka-ui                         | 11:55:17,523 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - This appender no longer admits a layout as a sub-component, set an encoder instead.
kafka-ui                         | 11:55:17,524 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - To ensure compatibility, wrapping your layout in LayoutWrappingEncoder.
kafka-ui                         | 11:55:17,524 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - See also http://logback.qos.ch/codes.html#layoutInsteadOfEncoder for details
kafka-ui                         | 11:55:17,526 |-INFO in ch.qos.logback.classic.model.processor.RootLoggerModelHandler - Setting level of ROOT logger to INFO
kafka-ui                         | 11:55:17,529 |-INFO in ch.qos.logback.classic.jul.LevelChangePropagator@4b14c583 - Propagating INFO level on Logger[ROOT] onto the JUL framework
kafka-ui                         | 11:55:17,535 |-INFO in ch.qos.logback.core.model.processor.AppenderRefModelHandler - Attaching appender named [STDOUT] to Logger[ROOT]
kafka-ui                         | 11:55:17,535 |-INFO in ch.qos.logback.core.model.processor.DefaultProcessor@65466a6a - End of configuration.
kafka-ui                         | 11:55:17,536 |-INFO in org.springframework.boot.logging.logback.SpringBootJoranConfigurator@4ddced80 - Registering current configuration as safe fallback point
kafka-ui                         | 
kafka-ui                         | 
kafka-ui                         |  _   _ ___    __             _                _          _  __      __ _
kafka-ui                         | | | | |_ _|  / _|___ _ _    /_\  _ __ __ _ __| |_  ___  | |/ /__ _ / _| |_____
kafka-ui                         | | |_| || |  |  _/ _ | '_|  / _ \| '_ / _` / _| ' \/ -_) | ' </ _` |  _| / / _`|
kafka-ui                         |  \___/|___| |_| \___|_|   /_/ \_| .__\__,_\__|_||_\___| |_|\_\__,_|_| |_\_\__,|
kafka-ui                         |                                  |_|                                             
kafka-ui                         | 
kafka-ui                         | 
schema-registry                  | ===> Running preflight checks ... 
schema-registry                  | ===> Check if Kafka is healthy ...
kafka-ui                         | [30m2023-08-03 11:55:18,211[0;39m [34mINFO [0;39m [[34mbackground-preinit[0;39m] [33mo.h.v.i.u.Version[0;39m: HV000001: Hibernate Validator 8.0.0.Final
kafka-ui                         | [30m2023-08-03 11:55:19,946[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Starting KafkaUiApplication using Java 17.0.6 with PID 1 (/kafka-ui-api.jar started by kafkaui in /)
kafka-ui                         | [30m2023-08-03 11:55:19,956[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Running with Spring Boot v3.0.6, Spring v6.0.8
kafka-ui                         | [30m2023-08-03 11:55:19,961[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: No active profile set, falling back to 1 default profile: "default"
kafka1                           | ===> Running preflight checks ... 
kafka1                           | ===> Check if /var/lib/kafka/data is writable ...
schema-registry                  | [2023-08-03 11:55:24,400] INFO AdminClientConfig values: 
schema-registry                  | 	auto.include.jmx.reporter = true
schema-registry                  | 	bootstrap.servers = [PLAINTEXT://kafka1:29092]
schema-registry                  | 	client.dns.lookup = use_all_dns_ips
schema-registry                  | 	client.id = 
schema-registry                  | 	connections.max.idle.ms = 300000
schema-registry                  | 	default.api.timeout.ms = 60000
schema-registry                  | 	metadata.max.age.ms = 300000
schema-registry                  | 	metric.reporters = []
schema-registry                  | 	metrics.num.samples = 2
schema-registry                  | 	metrics.recording.level = INFO
schema-registry                  | 	metrics.sample.window.ms = 30000
schema-registry                  | 	receive.buffer.bytes = 65536
schema-registry                  | 	reconnect.backoff.max.ms = 1000
schema-registry                  | 	reconnect.backoff.ms = 50
schema-registry                  | 	request.timeout.ms = 30000
schema-registry                  | 	retries = 2147483647
schema-registry                  | 	retry.backoff.ms = 100
schema-registry                  | 	sasl.client.callback.handler.class = null
schema-registry                  | 	sasl.jaas.config = null
schema-registry                  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
schema-registry                  | 	sasl.kerberos.min.time.before.relogin = 60000
schema-registry                  | 	sasl.kerberos.service.name = null
schema-registry                  | 	sasl.kerberos.ticket.renew.jitter = 0.05
schema-registry                  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
schema-registry                  | 	sasl.login.callback.handler.class = null
schema-registry                  | 	sasl.login.class = null
schema-registry                  | 	sasl.login.connect.timeout.ms = null
schema-registry                  | 	sasl.login.read.timeout.ms = null
schema-registry                  | 	sasl.login.refresh.buffer.seconds = 300
schema-registry                  | 	sasl.login.refresh.min.period.seconds = 60
schema-registry                  | 	sasl.login.refresh.window.factor = 0.8
schema-registry                  | 	sasl.login.refresh.window.jitter = 0.05
schema-registry                  | 	sasl.login.retry.backoff.max.ms = 10000
schema-registry                  | 	sasl.login.retry.backoff.ms = 100
schema-registry                  | 	sasl.mechanism = GSSAPI
schema-registry                  | 	sasl.oauthbearer.clock.skew.seconds = 30
schema-registry                  | 	sasl.oauthbearer.expected.audience = null
schema-registry                  | 	sasl.oauthbearer.expected.issuer = null
schema-registry                  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
schema-registry                  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
schema-registry                  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
schema-registry                  | 	sasl.oauthbearer.jwks.endpoint.url = null
schema-registry                  | 	sasl.oauthbearer.scope.claim.name = scope
schema-registry                  | 	sasl.oauthbearer.sub.claim.name = sub
schema-registry                  | 	sasl.oauthbearer.token.endpoint.url = null
schema-registry                  | 	security.protocol = PLAINTEXT
schema-registry                  | 	security.providers = null
schema-registry                  | 	send.buffer.bytes = 131072
schema-registry                  | 	socket.connection.setup.timeout.max.ms = 30000
schema-registry                  | 	socket.connection.setup.timeout.ms = 10000
schema-registry                  | 	ssl.cipher.suites = null
schema-registry                  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
schema-registry                  | 	ssl.endpoint.identification.algorithm = https
schema-registry                  | 	ssl.engine.factory.class = null
schema-registry                  | 	ssl.key.password = null
schema-registry                  | 	ssl.keymanager.algorithm = SunX509
schema-registry                  | 	ssl.keystore.certificate.chain = null
schema-registry                  | 	ssl.keystore.key = null
schema-registry                  | 	ssl.keystore.location = null
schema-registry                  | 	ssl.keystore.password = null
schema-registry                  | 	ssl.keystore.type = JKS
schema-registry                  | 	ssl.protocol = TLSv1.3
schema-registry                  | 	ssl.provider = null
schema-registry                  | 	ssl.secure.random.implementation = null
schema-registry                  | 	ssl.trustmanager.algorithm = PKIX
schema-registry                  | 	ssl.truststore.certificates = null
schema-registry                  | 	ssl.truststore.location = null
schema-registry                  | 	ssl.truststore.password = null
schema-registry                  | 	ssl.truststore.type = JKS
schema-registry                  |  (org.apache.kafka.clients.admin.AdminClientConfig)
kafka1                           | ===> Running in KRaft mode, skipping Zookeeper health check...
kafka1                           | /etc/confluent/docker/ensure: line 44: syntax error: unexpected end of file
kafka1 exited with code 2
schema-registry                  | [2023-08-03 11:55:27,293] INFO Kafka version: 7.4.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
schema-registry                  | [2023-08-03 11:55:27,297] INFO Kafka commitId: fed9c006bfc7ba5b (org.apache.kafka.common.utils.AppInfoParser)
schema-registry                  | [2023-08-03 11:55:27,297] INFO Kafka startTimeMs: 1691063727272 (org.apache.kafka.common.utils.AppInfoParser)
schema-registry                  | [2023-08-03 11:55:30,548] INFO [AdminClient clientId=adminclient-1] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
schema-registry                  | [2023-08-03 11:55:30,573] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.2:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
kafka_kraft-kafka-init-topics-1  | Waiting for Kafka to be ready...
schema-registry                  | [2023-08-03 11:55:33,567] INFO [AdminClient clientId=adminclient-1] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
schema-registry                  | [2023-08-03 11:55:33,569] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.2:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
schema-registry                  | [2023-08-03 11:55:36,646] INFO [AdminClient clientId=adminclient-1] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
schema-registry                  | [2023-08-03 11:55:36,650] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.2:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
kafka_kraft-kafka-init-topics-1  | log4j:ERROR setFile(null,true) call failed.
kafka_kraft-kafka-init-topics-1  | java.io.FileNotFoundException: /server.log (Permission denied)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.open0(Native Method)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.open(FileOutputStream.java:298)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:237)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:158)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.FileAppender.setFile(FileAppender.java:282)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:166)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.DailyRollingFileAppender.activateOptions(DailyRollingFileAppender.java:216)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:284)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:160)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:100)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:802)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:738)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:630)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:516)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:577)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.helpers.OptionConverter.selectAndConfigure(OptionConverter.java:504)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.LogManager.<clinit>(LogManager.java:119)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.impl.Reload4jLoggerFactory.<init>(Reload4jLoggerFactory.java:67)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.impl.StaticLoggerBinder.<init>(StaticLoggerBinder.java:72)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.impl.StaticLoggerBinder.<clinit>(StaticLoggerBinder.java:45)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:417)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:362)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:388)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at io.confluent.admin.utils.cli.KafkaReadyCommand.<clinit>(KafkaReadyCommand.java:53)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | log4j:ERROR Either File or DatePattern options are not set for appender [kafkaAppender].
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | log4j:ERROR setFile(null,true) call failed.
kafka_kraft-kafka-init-topics-1  | java.io.FileNotFoundException: /controller.log (Permission denied)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.open0(Native Method)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.open(FileOutputStream.java:298)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:237)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:158)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.FileAppender.setFile(FileAppender.java:282)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:166)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.DailyRollingFileAppender.activateOptions(DailyRollingFileAppender.java:216)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:284)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:160)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:100)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:802)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:738)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.parseCatsAndRenderers(PropertyConfigurator.java:652)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:518)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:577)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.helpers.OptionConverter.selectAndConfigure(OptionConverter.java:504)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.LogManager.<clinit>(LogManager.java:119)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.impl.Reload4jLoggerFactory.<init>(Reload4jLoggerFactory.java:67)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.impl.StaticLoggerBinder.<init>(StaticLoggerBinder.java:72)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.impl.StaticLoggerBinder.<clinit>(StaticLoggerBinder.java:45)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:417)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:362)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:388)
kafka_kraft-kafka-init-topics-1  | 	at io.confluent.admin.utils.cli.KafkaReadyCommand.<clinit>(KafkaReadyCommand.java:53)
kafka_kraft-kafka-init-topics-1  | log4j:ERROR Either File or DatePattern options are not set for appender [controllerAppender].
kafka_kraft-kafka-init-topics-1  | log4j:ERROR setFile(null,true) call failed.
kafka_kraft-kafka-init-topics-1  | java.io.FileNotFoundException: /kafka-request.log (Permission denied)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.open0(Native Method)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.open(FileOutputStream.java:298)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:237)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:158)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.FileAppender.setFile(FileAppender.java:282)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:166)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.DailyRollingFileAppender.activateOptions(DailyRollingFileAppender.java:216)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:284)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:160)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:100)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:802)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:738)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.parseCatsAndRenderers(PropertyConfigurator.java:652)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:518)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:577)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.helpers.OptionConverter.selectAndConfigure(OptionConverter.java:504)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.LogManager.<clinit>(LogManager.java:119)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.impl.Reload4jLoggerFactory.<init>(Reload4jLoggerFactory.java:67)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.impl.StaticLoggerBinder.<init>(StaticLoggerBinder.java:72)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.impl.StaticLoggerBinder.<clinit>(StaticLoggerBinder.java:45)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:417)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:362)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:388)
kafka_kraft-kafka-init-topics-1  | 	at io.confluent.admin.utils.cli.KafkaReadyCommand.<clinit>(KafkaReadyCommand.java:53)
kafka_kraft-kafka-init-topics-1  | log4j:ERROR Either File or DatePattern options are not set for appender [requestAppender].
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | log4j:ERROR setFile(null,true) call failed.
kafka_kraft-kafka-init-topics-1  | java.io.FileNotFoundException: /kafka-authorizer.log (Permission denied)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.open0(Native Method)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.open(FileOutputStream.java:298)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:237)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:158)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.FileAppender.setFile(FileAppender.java:282)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:166)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.DailyRollingFileAppender.activateOptions(DailyRollingFileAppender.java:216)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:284)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:160)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:100)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:802)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:738)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.parseCatsAndRenderers(PropertyConfigurator.java:652)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:518)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:577)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.helpers.OptionConverter.selectAndConfigure(OptionConverter.java:504)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.LogManager.<clinit>(LogManager.java:119)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.impl.Reload4jLoggerFactory.<init>(Reload4jLoggerFactory.java:67)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.impl.StaticLoggerBinder.<init>(StaticLoggerBinder.java:72)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.impl.StaticLoggerBinder.<clinit>(StaticLoggerBinder.java:45)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:417)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:362)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:388)
kafka_kraft-kafka-init-topics-1  | 	at io.confluent.admin.utils.cli.KafkaReadyCommand.<clinit>(KafkaReadyCommand.java:53)
kafka_kraft-kafka-init-topics-1  | log4j:ERROR Either File or DatePattern options are not set for appender [authorizerAppender].
kafka_kraft-kafka-init-topics-1  | log4j:ERROR setFile(null,true) call failed.
kafka_kraft-kafka-init-topics-1  | java.io.FileNotFoundException: /log-cleaner.log (Permission denied)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.open0(Native Method)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.open(FileOutputStream.java:298)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:237)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:158)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.FileAppender.setFile(FileAppender.java:282)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:166)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.DailyRollingFileAppender.activateOptions(DailyRollingFileAppender.java:216)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:284)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:160)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:100)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:802)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:738)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.parseCatsAndRenderers(PropertyConfigurator.java:652)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:518)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:577)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.helpers.OptionConverter.selectAndConfigure(OptionConverter.java:504)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.LogManager.<clinit>(LogManager.java:119)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.impl.Reload4jLoggerFactory.<init>(Reload4jLoggerFactory.java:67)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.impl.StaticLoggerBinder.<init>(StaticLoggerBinder.java:72)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.impl.StaticLoggerBinder.<clinit>(StaticLoggerBinder.java:45)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:417)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:362)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:388)
kafka_kraft-kafka-init-topics-1  | 	at io.confluent.admin.utils.cli.KafkaReadyCommand.<clinit>(KafkaReadyCommand.java:53)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | log4j:ERROR Either File or DatePattern options are not set for appender [cleanerAppender].
kafka_kraft-kafka-init-topics-1  | log4j:ERROR setFile(null,true) call failed.
kafka_kraft-kafka-init-topics-1  | java.io.FileNotFoundException: /state-change.log (Permission denied)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.open0(Native Method)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.open(FileOutputStream.java:298)
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:237)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:158)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.FileAppender.setFile(FileAppender.java:282)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:166)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.DailyRollingFileAppender.activateOptions(DailyRollingFileAppender.java:216)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:284)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:160)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:100)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:802)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:738)
kafka_kraft-kafka-init-topics-1  | 
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.parseCatsAndRenderers(PropertyConfigurator.java:652)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:518)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:577)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.helpers.OptionConverter.selectAndConfigure(OptionConverter.java:504)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.log4j.LogManager.<clinit>(LogManager.java:119)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.impl.Reload4jLoggerFactory.<init>(Reload4jLoggerFactory.java:67)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.impl.StaticLoggerBinder.<init>(StaticLoggerBinder.java:72)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.impl.StaticLoggerBinder.<clinit>(StaticLoggerBinder.java:45)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:417)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:362)
kafka_kraft-kafka-init-topics-1  | 	at org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:388)
kafka_kraft-kafka-init-topics-1  | 	at io.confluent.admin.utils.cli.KafkaReadyCommand.<clinit>(KafkaReadyCommand.java:53)
kafka_kraft-kafka-init-topics-1  | log4j:ERROR Either File or DatePattern options are not set for appender [stateChangeAppender].
kafka_kraft-kafka-init-topics-1  | [2023-08-03 11:55:38,228] INFO AdminClientConfig values: 
kafka_kraft-kafka-init-topics-1  | 	auto.include.jmx.reporter = true
kafka_kraft-kafka-init-topics-1  | 	bootstrap.servers = [kafka1:29092]
kafka_kraft-kafka-init-topics-1  | 	client.dns.lookup = use_all_dns_ips
kafka_kraft-kafka-init-topics-1  | 	client.id = 
kafka_kraft-kafka-init-topics-1  | 	connections.max.idle.ms = 300000
kafka_kraft-kafka-init-topics-1  | 	default.api.timeout.ms = 60000
kafka_kraft-kafka-init-topics-1  | 	metadata.max.age.ms = 300000
kafka_kraft-kafka-init-topics-1  | 	metric.reporters = []
kafka_kraft-kafka-init-topics-1  | 	metrics.num.samples = 2
kafka_kraft-kafka-init-topics-1  | 	metrics.recording.level = INFO
kafka_kraft-kafka-init-topics-1  | 	metrics.sample.window.ms = 30000
kafka_kraft-kafka-init-topics-1  | 	receive.buffer.bytes = 65536
kafka_kraft-kafka-init-topics-1  | 	reconnect.backoff.max.ms = 1000
kafka_kraft-kafka-init-topics-1  | 	reconnect.backoff.ms = 50
kafka_kraft-kafka-init-topics-1  | 	request.timeout.ms = 30000
kafka_kraft-kafka-init-topics-1  | 	retries = 2147483647
kafka_kraft-kafka-init-topics-1  | 	retry.backoff.ms = 100
kafka_kraft-kafka-init-topics-1  | 	sasl.client.callback.handler.class = null
kafka_kraft-kafka-init-topics-1  | 	sasl.jaas.config = null
kafka_kraft-kafka-init-topics-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka_kraft-kafka-init-topics-1  | 	sasl.kerberos.min.time.before.relogin = 60000
kafka_kraft-kafka-init-topics-1  | 	sasl.kerberos.service.name = null
kafka_kraft-kafka-init-topics-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka_kraft-kafka-init-topics-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka_kraft-kafka-init-topics-1  | 	sasl.login.callback.handler.class = null
kafka_kraft-kafka-init-topics-1  | 	sasl.login.class = null
kafka_kraft-kafka-init-topics-1  | 	sasl.login.connect.timeout.ms = null
kafka_kraft-kafka-init-topics-1  | 	sasl.login.read.timeout.ms = null
kafka_kraft-kafka-init-topics-1  | 	sasl.login.refresh.buffer.seconds = 300
kafka_kraft-kafka-init-topics-1  | 	sasl.login.refresh.min.period.seconds = 60
kafka_kraft-kafka-init-topics-1  | 	sasl.login.refresh.window.factor = 0.8
kafka_kraft-kafka-init-topics-1  | 	sasl.login.refresh.window.jitter = 0.05
kafka_kraft-kafka-init-topics-1  | 	sasl.login.retry.backoff.max.ms = 10000
kafka_kraft-kafka-init-topics-1  | 	sasl.login.retry.backoff.ms = 100
kafka_kraft-kafka-init-topics-1  | 	sasl.mechanism = GSSAPI
kafka_kraft-kafka-init-topics-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka_kraft-kafka-init-topics-1  | 	sasl.oauthbearer.expected.audience = null
kafka_kraft-kafka-init-topics-1  | 	sasl.oauthbearer.expected.issuer = null
kafka_kraft-kafka-init-topics-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka_kraft-kafka-init-topics-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka_kraft-kafka-init-topics-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka_kraft-kafka-init-topics-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka_kraft-kafka-init-topics-1  | 	sasl.oauthbearer.scope.claim.name = scope
kafka_kraft-kafka-init-topics-1  | 	sasl.oauthbearer.sub.claim.name = sub
kafka_kraft-kafka-init-topics-1  | 	sasl.oauthbearer.token.endpoint.url = null
kafka_kraft-kafka-init-topics-1  | 	security.protocol = PLAINTEXT
kafka_kraft-kafka-init-topics-1  | 	security.providers = null
kafka_kraft-kafka-init-topics-1  | 	send.buffer.bytes = 131072
kafka_kraft-kafka-init-topics-1  | 	socket.connection.setup.timeout.max.ms = 30000
kafka_kraft-kafka-init-topics-1  | 	socket.connection.setup.timeout.ms = 10000
kafka_kraft-kafka-init-topics-1  | 	ssl.cipher.suites = null
kafka_kraft-kafka-init-topics-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka_kraft-kafka-init-topics-1  | 	ssl.endpoint.identification.algorithm = https
kafka_kraft-kafka-init-topics-1  | 	ssl.engine.factory.class = null
kafka_kraft-kafka-init-topics-1  | 	ssl.key.password = null
kafka_kraft-kafka-init-topics-1  | 	ssl.keymanager.algorithm = SunX509
kafka_kraft-kafka-init-topics-1  | 	ssl.keystore.certificate.chain = null
kafka_kraft-kafka-init-topics-1  | 	ssl.keystore.key = null
kafka_kraft-kafka-init-topics-1  | 	ssl.keystore.location = null
kafka_kraft-kafka-init-topics-1  | 	ssl.keystore.password = null
kafka_kraft-kafka-init-topics-1  | 	ssl.keystore.type = JKS
kafka_kraft-kafka-init-topics-1  | 	ssl.protocol = TLSv1.3
kafka_kraft-kafka-init-topics-1  | 	ssl.provider = null
kafka_kraft-kafka-init-topics-1  | 	ssl.secure.random.implementation = null
kafka_kraft-kafka-init-topics-1  | 	ssl.trustmanager.algorithm = PKIX
kafka_kraft-kafka-init-topics-1  | 	ssl.truststore.certificates = null
kafka_kraft-kafka-init-topics-1  | 	ssl.truststore.location = null
kafka_kraft-kafka-init-topics-1  | 	ssl.truststore.password = null
kafka_kraft-kafka-init-topics-1  | 	ssl.truststore.type = JKS
kafka_kraft-kafka-init-topics-1  |  (org.apache.kafka.clients.admin.AdminClientConfig)
kafka_kraft-kafka-init-topics-1  | [2023-08-03 11:55:38,598] WARN Couldn't resolve server kafka1:29092 from bootstrap.servers as DNS resolution failed for kafka1 (org.apache.kafka.clients.ClientUtils)
kafka_kraft-kafka-init-topics-1  | [2023-08-03 11:55:38,600] ERROR Error while running kafka-ready. (io.confluent.admin.utils.cli.KafkaReadyCommand)
kafka_kraft-kafka-init-topics-1  | org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
kafka_kraft-kafka-init-topics-1  | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:551)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:144)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:49)
kafka_kraft-kafka-init-topics-1  | 	at io.confluent.admin.utils.ClusterStatus.isKafkaReady(ClusterStatus.java:136)
kafka_kraft-kafka-init-topics-1  | 	at io.confluent.admin.utils.cli.KafkaReadyCommand.main(KafkaReadyCommand.java:149)
kafka_kraft-kafka-init-topics-1  | Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
kafka_kraft-kafka-init-topics-1  | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
kafka_kraft-kafka-init-topics-1  | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:508)
kafka_kraft-kafka-init-topics-1  | 	... 4 more
kafka_kraft-kafka-init-topics-1  | Using log4j config /etc/kafka/log4j.properties
kafka_kraft-kafka-init-topics-1 exited with code 1
schema-registry                  | [2023-08-03 11:55:39,711] INFO [AdminClient clientId=adminclient-1] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
schema-registry                  | [2023-08-03 11:55:39,711] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.2:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
schema-registry                  | [2023-08-03 11:55:42,784] INFO [AdminClient clientId=adminclient-1] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
schema-registry                  | [2023-08-03 11:55:42,794] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.2:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
kafka-ui                         | [30m2023-08-03 11:55:45,650[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.s.SerdesInitializer[0;39m: Configuring serdes for cluster local
schema-registry                  | [2023-08-03 11:55:45,854] INFO [AdminClient clientId=adminclient-1] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
schema-registry                  | [2023-08-03 11:55:45,855] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.2:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
schema-registry                  | [2023-08-03 11:55:48,928] INFO [AdminClient clientId=adminclient-1] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
schema-registry                  | [2023-08-03 11:55:48,929] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.2:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
schema-registry                  | [2023-08-03 11:55:51,998] INFO [AdminClient clientId=adminclient-1] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
schema-registry                  | [2023-08-03 11:55:51,999] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.2:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
kafka-ui                         | [30m2023-08-03 11:55:52,566[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.e.w.EndpointLinksResolver[0;39m: Exposing 2 endpoint(s) beneath base path '/actuator'
kafka-ui                         | [30m2023-08-03 11:55:53,086[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.s.r.ReactiveUserDetailsServiceAutoConfiguration[0;39m: 
kafka-ui                         | 
kafka-ui                         | Using generated security password: e533f9f6-769b-48e2-85a0-cb836da92ea4
kafka-ui                         | 
kafka-ui                         | 
kafka-ui                         | [30m2023-08-03 11:55:53,705[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.c.a.DisabledAuthSecurityConfig[0;39m: Authentication is disabled. Access will be unrestricted.
schema-registry                  | [2023-08-03 11:55:55,075] INFO [AdminClient clientId=adminclient-1] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
schema-registry                  | [2023-08-03 11:55:55,075] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.2:29092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
schema-registry                  | [2023-08-03 11:55:56,010] WARN [AdminClient clientId=adminclient-1] Error connecting to node kafka1:29092 (id: -1 rack: null) (org.apache.kafka.clients.NetworkClient)
schema-registry                  | java.net.UnknownHostException: kafka1: Name or service not known
schema-registry                  | 	at java.base/java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
schema-registry                  | 	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:929)
schema-registry                  | 	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1534)
schema-registry                  | 	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:848)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1524)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1382)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
schema-registry                  | 	at org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)
schema-registry                  | 	at org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)
schema-registry                  | 	at java.base/java.lang.Thread.run(Thread.java:829)
kafka-ui                         | [30m2023-08-03 11:55:56,104[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.w.e.n.NettyWebServer[0;39m: Netty started on port 8080
kafka-ui                         | [30m2023-08-03 11:55:56,213[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Started KafkaUiApplication in 43.292 seconds (process running for 52.257)
schema-registry                  | [2023-08-03 11:55:57,055] WARN [AdminClient clientId=adminclient-1] Error connecting to node kafka1:29092 (id: -1 rack: null) (org.apache.kafka.clients.NetworkClient)
schema-registry                  | java.net.UnknownHostException: kafka1
schema-registry                  | 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1524)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1382)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
schema-registry                  | 	at org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)
schema-registry                  | 	at org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)
schema-registry                  | 	at java.base/java.lang.Thread.run(Thread.java:829)
schema-registry                  | [2023-08-03 11:55:57,331] INFO [AdminClient clientId=adminclient-1] Metadata update failed (org.apache.kafka.clients.admin.internals.AdminMetadataManager)
schema-registry                  | org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: fetchMetadata
schema-registry                  | [2023-08-03 11:55:58,239] WARN [AdminClient clientId=adminclient-1] Error connecting to node kafka1:29092 (id: -1 rack: null) (org.apache.kafka.clients.NetworkClient)
schema-registry                  | java.net.UnknownHostException: kafka1
schema-registry                  | 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1524)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1382)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
schema-registry                  | 	at org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)
schema-registry                  | 	at org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)
schema-registry                  | 	at java.base/java.lang.Thread.run(Thread.java:829)
kafka-ui                         | [30m2023-08-03 11:55:58,721[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
kafka-ui                         | [30m2023-08-03 11:55:58,782[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
kafka-ui                         | 	bootstrap.servers = [kafka1:29092]
kafka-ui                         | 	client.dns.lookup = use_all_dns_ips
kafka-ui                         | 	client.id = kafka-ui-admin-1691063758-1
kafka-ui                         | 	connections.max.idle.ms = 300000
kafka-ui                         | 	default.api.timeout.ms = 60000
kafka-ui                         | 	metadata.max.age.ms = 300000
kafka-ui                         | 	metric.reporters = []
kafka-ui                         | 	metrics.num.samples = 2
kafka-ui                         | 	metrics.recording.level = INFO
kafka-ui                         | 	metrics.sample.window.ms = 30000
kafka-ui                         | 	receive.buffer.bytes = 65536
kafka-ui                         | 	reconnect.backoff.max.ms = 1000
kafka-ui                         | 	reconnect.backoff.ms = 50
kafka-ui                         | 	request.timeout.ms = 30000
kafka-ui                         | 	retries = 2147483647
kafka-ui                         | 	retry.backoff.ms = 100
kafka-ui                         | 	sasl.client.callback.handler.class = null
kafka-ui                         | 	sasl.jaas.config = null
kafka-ui                         | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-ui                         | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-ui                         | 	sasl.kerberos.service.name = null
kafka-ui                         | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-ui                         | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-ui                         | 	sasl.login.callback.handler.class = null
kafka-ui                         | 	sasl.login.class = null
kafka-ui                         | 	sasl.login.connect.timeout.ms = null
kafka-ui                         | 	sasl.login.read.timeout.ms = null
kafka-ui                         | 	sasl.login.refresh.buffer.seconds = 300
kafka-ui                         | 	sasl.login.refresh.min.period.seconds = 60
kafka-ui                         | 	sasl.login.refresh.window.factor = 0.8
kafka-ui                         | 	sasl.login.refresh.window.jitter = 0.05
kafka-ui                         | 	sasl.login.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.login.retry.backoff.ms = 100
kafka-ui                         | 	sasl.mechanism = GSSAPI
kafka-ui                         | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-ui                         | 	sasl.oauthbearer.expected.audience = null
kafka-ui                         | 	sasl.oauthbearer.expected.issuer = null
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-ui                         | 	sasl.oauthbearer.scope.claim.name = scope
kafka-ui                         | 	sasl.oauthbearer.sub.claim.name = sub
kafka-ui                         | 	sasl.oauthbearer.token.endpoint.url = null
kafka-ui                         | 	security.protocol = PLAINTEXT
kafka-ui                         | 	security.providers = null
kafka-ui                         | 	send.buffer.bytes = 131072
kafka-ui                         | 	socket.connection.setup.timeout.max.ms = 30000
kafka-ui                         | 	socket.connection.setup.timeout.ms = 10000
kafka-ui                         | 	ssl.cipher.suites = null
kafka-ui                         | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-ui                         | 	ssl.endpoint.identification.algorithm = https
kafka-ui                         | 	ssl.engine.factory.class = null
kafka-ui                         | 	ssl.key.password = null
kafka-ui                         | 	ssl.keymanager.algorithm = SunX509
kafka-ui                         | 	ssl.keystore.certificate.chain = null
kafka-ui                         | 	ssl.keystore.key = null
kafka-ui                         | 	ssl.keystore.location = null
kafka-ui                         | 	ssl.keystore.password = null
kafka-ui                         | 	ssl.keystore.type = JKS
kafka-ui                         | 	ssl.protocol = TLSv1.3
kafka-ui                         | 	ssl.provider = null
kafka-ui                         | 	ssl.secure.random.implementation = null
kafka-ui                         | 	ssl.trustmanager.algorithm = PKIX
kafka-ui                         | 	ssl.truststore.certificates = null
kafka-ui                         | 	ssl.truststore.location = null
kafka-ui                         | 	ssl.truststore.password = null
kafka-ui                         | 	ssl.truststore.type = JKS
kafka-ui                         | 
kafka-ui                         | 
schema-registry                  | [2023-08-03 11:55:59,154] WARN [AdminClient clientId=adminclient-1] Error connecting to node kafka1:29092 (id: -1 rack: null) (org.apache.kafka.clients.NetworkClient)
schema-registry                  | java.net.UnknownHostException: kafka1
schema-registry                  | 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1524)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1382)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
schema-registry                  | 	at org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)
schema-registry                  | 	at org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)
schema-registry                  | 	at java.base/java.lang.Thread.run(Thread.java:829)
schema-registry                  | [2023-08-03 11:56:00,263] WARN [AdminClient clientId=adminclient-1] Error connecting to node kafka1:29092 (id: -1 rack: null) (org.apache.kafka.clients.NetworkClient)
schema-registry                  | java.net.UnknownHostException: kafka1
schema-registry                  | 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1524)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1382)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
schema-registry                  | 	at org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)
schema-registry                  | 	at org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)
schema-registry                  | 	at java.base/java.lang.Thread.run(Thread.java:829)
schema-registry                  | [2023-08-03 11:56:01,470] WARN [AdminClient clientId=adminclient-1] Error connecting to node kafka1:29092 (id: -1 rack: null) (org.apache.kafka.clients.NetworkClient)
schema-registry                  | java.net.UnknownHostException: kafka1
schema-registry                  | 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1524)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1382)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
schema-registry                  | 	at org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)
schema-registry                  | 	at org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)
schema-registry                  | 	at java.base/java.lang.Thread.run(Thread.java:829)
schema-registry                  | [2023-08-03 11:56:02,683] WARN [AdminClient clientId=adminclient-1] Error connecting to node kafka1:29092 (id: -1 rack: null) (org.apache.kafka.clients.NetworkClient)
schema-registry                  | java.net.UnknownHostException: kafka1
schema-registry                  | 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1524)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1382)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
schema-registry                  | 	at org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)
schema-registry                  | 	at org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)
schema-registry                  | 	at java.base/java.lang.Thread.run(Thread.java:829)
schema-registry                  | [2023-08-03 11:56:03,594] WARN [AdminClient clientId=adminclient-1] Error connecting to node kafka1:29092 (id: -1 rack: null) (org.apache.kafka.clients.NetworkClient)
schema-registry                  | java.net.UnknownHostException: kafka1
schema-registry                  | 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1524)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1382)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
schema-registry                  | 	at org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)
schema-registry                  | 	at org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)
schema-registry                  | 	at java.base/java.lang.Thread.run(Thread.java:829)
kafka-ui                         | [30m2023-08-03 11:56:03,974[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka1:29092 from bootstrap.servers as DNS resolution failed for kafka1
kafka-ui                         | [30m2023-08-03 11:56:03,992[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
kafka-ui                         | java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
kafka-ui                         | 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
kafka-ui                         | 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
kafka-ui                         | 	at reactor.core.publisher.Operators.error(Operators.java:198)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
kafka-ui                         | 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
kafka-ui                         | 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
kafka-ui                         | 	at reactor.core.publisher.Operators.complete(Operators.java:137)
kafka-ui                         | 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
kafka-ui                         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
kafka-ui                         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
kafka-ui                         | 	at java.base/java.lang.Thread.run(Thread.java:833)
kafka-ui                         | Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
kafka-ui                         | 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
kafka-ui                         | 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
kafka-ui                         | 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
kafka-ui                         | 	... 16 common frames omitted
kafka-ui                         | Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
kafka-ui                         | 	... 22 common frames omitted
kafka-ui                         | [30m2023-08-03 11:56:04,002[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
schema-registry                  | [2023-08-03 11:56:04,702] WARN [AdminClient clientId=adminclient-1] Error connecting to node kafka1:29092 (id: -1 rack: null) (org.apache.kafka.clients.NetworkClient)
schema-registry                  | java.net.UnknownHostException: kafka1
schema-registry                  | 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1524)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1382)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
schema-registry                  | 	at org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)
schema-registry                  | 	at org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)
schema-registry                  | 	at java.base/java.lang.Thread.run(Thread.java:829)
schema-registry                  | [2023-08-03 11:56:05,709] WARN [AdminClient clientId=adminclient-1] Error connecting to node kafka1:29092 (id: -1 rack: null) (org.apache.kafka.clients.NetworkClient)
schema-registry                  | java.net.UnknownHostException: kafka1
schema-registry                  | 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1524)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1382)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
schema-registry                  | 	at org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)
schema-registry                  | 	at org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)
schema-registry                  | 	at java.base/java.lang.Thread.run(Thread.java:829)
schema-registry                  | [2023-08-03 11:56:06,999] WARN [AdminClient clientId=adminclient-1] Error connecting to node kafka1:29092 (id: -1 rack: null) (org.apache.kafka.clients.NetworkClient)
schema-registry                  | java.net.UnknownHostException: kafka1: Name or service not known
schema-registry                  | 	at java.base/java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
schema-registry                  | 	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:929)
schema-registry                  | 	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1534)
schema-registry                  | 	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:848)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1524)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1382)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
schema-registry                  | 	at org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)
schema-registry                  | 	at org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)
schema-registry                  | 	at java.base/java.lang.Thread.run(Thread.java:829)
schema-registry                  | [2023-08-03 11:56:07,372] ERROR Error while getting broker list. (io.confluent.admin.utils.ClusterStatus)
schema-registry                  | java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: listNodes
schema-registry                  | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
schema-registry                  | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
schema-registry                  | 	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)
schema-registry                  | 	at io.confluent.admin.utils.ClusterStatus.isKafkaReady(ClusterStatus.java:147)
schema-registry                  | 	at io.confluent.admin.utils.cli.KafkaReadyCommand.main(KafkaReadyCommand.java:149)
schema-registry                  | Caused by: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: listNodes
schema-registry                  | [2023-08-03 11:56:07,774] WARN [AdminClient clientId=adminclient-1] Error connecting to node kafka1:29092 (id: -1 rack: null) (org.apache.kafka.clients.NetworkClient)
schema-registry                  | java.net.UnknownHostException: kafka1
schema-registry                  | 	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1524)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1382)
schema-registry                  | 	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
schema-registry                  | 	at org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)
schema-registry                  | 	at org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)
schema-registry                  | 	at org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)
schema-registry                  | 	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)
schema-registry                  | 	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)
schema-registry                  | 	at java.base/java.lang.Thread.run(Thread.java:829)
schema-registry                  | [2023-08-03 11:56:08,374] INFO Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ... (io.confluent.admin.utils.ClusterStatus)
schema-registry                  | [2023-08-03 11:56:08,375] ERROR Expected 1 brokers but found only 0. Brokers found []. (io.confluent.admin.utils.ClusterStatus)
schema-registry                  | Using log4j config /etc/schema-registry/log4j.properties
schema-registry exited with code 1
kafka-ui                         | [30m2023-08-03 11:56:26,198[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
kafka-ui                         | [30m2023-08-03 11:56:26,201[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
kafka-ui                         | 	bootstrap.servers = [kafka1:29092]
kafka-ui                         | 	client.dns.lookup = use_all_dns_ips
kafka-ui                         | 	client.id = kafka-ui-admin-1691063786-2
kafka-ui                         | 	connections.max.idle.ms = 300000
kafka-ui                         | 	default.api.timeout.ms = 60000
kafka-ui                         | 	metadata.max.age.ms = 300000
kafka-ui                         | 	metric.reporters = []
kafka-ui                         | 	metrics.num.samples = 2
kafka-ui                         | 	metrics.recording.level = INFO
kafka-ui                         | 	metrics.sample.window.ms = 30000
kafka-ui                         | 	receive.buffer.bytes = 65536
kafka-ui                         | 	reconnect.backoff.max.ms = 1000
kafka-ui                         | 	reconnect.backoff.ms = 50
kafka-ui                         | 	request.timeout.ms = 30000
kafka-ui                         | 	retries = 2147483647
kafka-ui                         | 	retry.backoff.ms = 100
kafka-ui                         | 	sasl.client.callback.handler.class = null
kafka-ui                         | 	sasl.jaas.config = null
kafka-ui                         | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-ui                         | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-ui                         | 	sasl.kerberos.service.name = null
kafka-ui                         | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-ui                         | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-ui                         | 	sasl.login.callback.handler.class = null
kafka-ui                         | 	sasl.login.class = null
kafka-ui                         | 	sasl.login.connect.timeout.ms = null
kafka-ui                         | 	sasl.login.read.timeout.ms = null
kafka-ui                         | 	sasl.login.refresh.buffer.seconds = 300
kafka-ui                         | 	sasl.login.refresh.min.period.seconds = 60
kafka-ui                         | 	sasl.login.refresh.window.factor = 0.8
kafka-ui                         | 	sasl.login.refresh.window.jitter = 0.05
kafka-ui                         | 	sasl.login.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.login.retry.backoff.ms = 100
kafka-ui                         | 	sasl.mechanism = GSSAPI
kafka-ui                         | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-ui                         | 	sasl.oauthbearer.expected.audience = null
kafka-ui                         | 	sasl.oauthbearer.expected.issuer = null
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-ui                         | 	sasl.oauthbearer.scope.claim.name = scope
kafka-ui                         | 	sasl.oauthbearer.sub.claim.name = sub
kafka-ui                         | 	sasl.oauthbearer.token.endpoint.url = null
kafka-ui                         | 	security.protocol = PLAINTEXT
kafka-ui                         | 	security.providers = null
kafka-ui                         | 	send.buffer.bytes = 131072
kafka-ui                         | 	socket.connection.setup.timeout.max.ms = 30000
kafka-ui                         | 	socket.connection.setup.timeout.ms = 10000
kafka-ui                         | 	ssl.cipher.suites = null
kafka-ui                         | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-ui                         | 	ssl.endpoint.identification.algorithm = https
kafka-ui                         | 	ssl.engine.factory.class = null
kafka-ui                         | 	ssl.key.password = null
kafka-ui                         | 	ssl.keymanager.algorithm = SunX509
kafka-ui                         | 	ssl.keystore.certificate.chain = null
kafka-ui                         | 	ssl.keystore.key = null
kafka-ui                         | 	ssl.keystore.location = null
kafka-ui                         | 	ssl.keystore.password = null
kafka-ui                         | 	ssl.keystore.type = JKS
kafka-ui                         | 	ssl.protocol = TLSv1.3
kafka-ui                         | 	ssl.provider = null
kafka-ui                         | 	ssl.secure.random.implementation = null
kafka-ui                         | 	ssl.trustmanager.algorithm = PKIX
kafka-ui                         | 	ssl.truststore.certificates = null
kafka-ui                         | 	ssl.truststore.location = null
kafka-ui                         | 	ssl.truststore.password = null
kafka-ui                         | 	ssl.truststore.type = JKS
kafka-ui                         | 
kafka-ui                         | 
kafka-ui                         | [30m2023-08-03 11:56:31,206[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka1:29092 from bootstrap.servers as DNS resolution failed for kafka1
kafka-ui                         | [30m2023-08-03 11:56:31,207[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
kafka-ui                         | java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
kafka-ui                         | 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
kafka-ui                         | 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
kafka-ui                         | 	at reactor.core.publisher.Operators.error(Operators.java:198)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
kafka-ui                         | 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
kafka-ui                         | 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
kafka-ui                         | 	at reactor.core.publisher.Operators.complete(Operators.java:137)
kafka-ui                         | 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
kafka-ui                         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
kafka-ui                         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
kafka-ui                         | 	at java.base/java.lang.Thread.run(Thread.java:833)
kafka-ui                         | Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
kafka-ui                         | 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
kafka-ui                         | 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
kafka-ui                         | 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
kafka-ui                         | 	... 16 common frames omitted
kafka-ui                         | Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
kafka-ui                         | 	... 22 common frames omitted
kafka-ui                         | [30m2023-08-03 11:56:31,209[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
kafka-ui                         | [30m2023-08-03 11:56:56,199[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
kafka-ui                         | [30m2023-08-03 11:56:56,201[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
kafka-ui                         | 	bootstrap.servers = [kafka1:29092]
kafka-ui                         | 	client.dns.lookup = use_all_dns_ips
kafka-ui                         | 	client.id = kafka-ui-admin-1691063816-3
kafka-ui                         | 	connections.max.idle.ms = 300000
kafka-ui                         | 	default.api.timeout.ms = 60000
kafka-ui                         | 	metadata.max.age.ms = 300000
kafka-ui                         | 	metric.reporters = []
kafka-ui                         | 	metrics.num.samples = 2
kafka-ui                         | 	metrics.recording.level = INFO
kafka-ui                         | 	metrics.sample.window.ms = 30000
kafka-ui                         | 	receive.buffer.bytes = 65536
kafka-ui                         | 	reconnect.backoff.max.ms = 1000
kafka-ui                         | 	reconnect.backoff.ms = 50
kafka-ui                         | 	request.timeout.ms = 30000
kafka-ui                         | 	retries = 2147483647
kafka-ui                         | 	retry.backoff.ms = 100
kafka-ui                         | 	sasl.client.callback.handler.class = null
kafka-ui                         | 	sasl.jaas.config = null
kafka-ui                         | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-ui                         | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-ui                         | 	sasl.kerberos.service.name = null
kafka-ui                         | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-ui                         | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-ui                         | 	sasl.login.callback.handler.class = null
kafka-ui                         | 	sasl.login.class = null
kafka-ui                         | 	sasl.login.connect.timeout.ms = null
kafka-ui                         | 	sasl.login.read.timeout.ms = null
kafka-ui                         | 	sasl.login.refresh.buffer.seconds = 300
kafka-ui                         | 	sasl.login.refresh.min.period.seconds = 60
kafka-ui                         | 	sasl.login.refresh.window.factor = 0.8
kafka-ui                         | 	sasl.login.refresh.window.jitter = 0.05
kafka-ui                         | 	sasl.login.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.login.retry.backoff.ms = 100
kafka-ui                         | 	sasl.mechanism = GSSAPI
kafka-ui                         | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-ui                         | 	sasl.oauthbearer.expected.audience = null
kafka-ui                         | 	sasl.oauthbearer.expected.issuer = null
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-ui                         | 	sasl.oauthbearer.scope.claim.name = scope
kafka-ui                         | 	sasl.oauthbearer.sub.claim.name = sub
kafka-ui                         | 	sasl.oauthbearer.token.endpoint.url = null
kafka-ui                         | 	security.protocol = PLAINTEXT
kafka-ui                         | 	security.providers = null
kafka-ui                         | 	send.buffer.bytes = 131072
kafka-ui                         | 	socket.connection.setup.timeout.max.ms = 30000
kafka-ui                         | 	socket.connection.setup.timeout.ms = 10000
kafka-ui                         | 	ssl.cipher.suites = null
kafka-ui                         | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-ui                         | 	ssl.endpoint.identification.algorithm = https
kafka-ui                         | 	ssl.engine.factory.class = null
kafka-ui                         | 	ssl.key.password = null
kafka-ui                         | 	ssl.keymanager.algorithm = SunX509
kafka-ui                         | 	ssl.keystore.certificate.chain = null
kafka-ui                         | 	ssl.keystore.key = null
kafka-ui                         | 	ssl.keystore.location = null
kafka-ui                         | 	ssl.keystore.password = null
kafka-ui                         | 	ssl.keystore.type = JKS
kafka-ui                         | 	ssl.protocol = TLSv1.3
kafka-ui                         | 	ssl.provider = null
kafka-ui                         | 	ssl.secure.random.implementation = null
kafka-ui                         | 	ssl.trustmanager.algorithm = PKIX
kafka-ui                         | 	ssl.truststore.certificates = null
kafka-ui                         | 	ssl.truststore.location = null
kafka-ui                         | 	ssl.truststore.password = null
kafka-ui                         | 	ssl.truststore.type = JKS
kafka-ui                         | 
kafka-ui                         | 
kafka-ui                         | [30m2023-08-03 11:57:01,206[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka1:29092 from bootstrap.servers as DNS resolution failed for kafka1
kafka-ui                         | [30m2023-08-03 11:57:01,207[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
kafka-ui                         | java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
kafka-ui                         | 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
kafka-ui                         | 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
kafka-ui                         | 	at reactor.core.publisher.Operators.error(Operators.java:198)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
kafka-ui                         | 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
kafka-ui                         | 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
kafka-ui                         | 	at reactor.core.publisher.Operators.complete(Operators.java:137)
kafka-ui                         | 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
kafka-ui                         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
kafka-ui                         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
kafka-ui                         | 	at java.base/java.lang.Thread.run(Thread.java:833)
kafka-ui                         | Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
kafka-ui                         | 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
kafka-ui                         | 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
kafka-ui                         | 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
kafka-ui                         | 	... 16 common frames omitted
kafka-ui                         | Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
kafka-ui                         | 	... 22 common frames omitted
kafka-ui                         | [30m2023-08-03 11:57:01,209[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
kafka-ui                         | [30m2023-08-03 11:57:26,198[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
kafka-ui                         | [30m2023-08-03 11:57:26,201[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
kafka-ui                         | 	bootstrap.servers = [kafka1:29092]
kafka-ui                         | 	client.dns.lookup = use_all_dns_ips
kafka-ui                         | 	client.id = kafka-ui-admin-1691063846-4
kafka-ui                         | 	connections.max.idle.ms = 300000
kafka-ui                         | 	default.api.timeout.ms = 60000
kafka-ui                         | 	metadata.max.age.ms = 300000
kafka-ui                         | 	metric.reporters = []
kafka-ui                         | 	metrics.num.samples = 2
kafka-ui                         | 	metrics.recording.level = INFO
kafka-ui                         | 	metrics.sample.window.ms = 30000
kafka-ui                         | 	receive.buffer.bytes = 65536
kafka-ui                         | 	reconnect.backoff.max.ms = 1000
kafka-ui                         | 	reconnect.backoff.ms = 50
kafka-ui                         | 	request.timeout.ms = 30000
kafka-ui                         | 	retries = 2147483647
kafka-ui                         | 	retry.backoff.ms = 100
kafka-ui                         | 	sasl.client.callback.handler.class = null
kafka-ui                         | 	sasl.jaas.config = null
kafka-ui                         | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-ui                         | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-ui                         | 	sasl.kerberos.service.name = null
kafka-ui                         | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-ui                         | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-ui                         | 	sasl.login.callback.handler.class = null
kafka-ui                         | 	sasl.login.class = null
kafka-ui                         | 	sasl.login.connect.timeout.ms = null
kafka-ui                         | 	sasl.login.read.timeout.ms = null
kafka-ui                         | 	sasl.login.refresh.buffer.seconds = 300
kafka-ui                         | 	sasl.login.refresh.min.period.seconds = 60
kafka-ui                         | 	sasl.login.refresh.window.factor = 0.8
kafka-ui                         | 	sasl.login.refresh.window.jitter = 0.05
kafka-ui                         | 	sasl.login.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.login.retry.backoff.ms = 100
kafka-ui                         | 	sasl.mechanism = GSSAPI
kafka-ui                         | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-ui                         | 	sasl.oauthbearer.expected.audience = null
kafka-ui                         | 	sasl.oauthbearer.expected.issuer = null
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-ui                         | 	sasl.oauthbearer.scope.claim.name = scope
kafka-ui                         | 	sasl.oauthbearer.sub.claim.name = sub
kafka-ui                         | 	sasl.oauthbearer.token.endpoint.url = null
kafka-ui                         | 	security.protocol = PLAINTEXT
kafka-ui                         | 	security.providers = null
kafka-ui                         | 	send.buffer.bytes = 131072
kafka-ui                         | 	socket.connection.setup.timeout.max.ms = 30000
kafka-ui                         | 	socket.connection.setup.timeout.ms = 10000
kafka-ui                         | 	ssl.cipher.suites = null
kafka-ui                         | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-ui                         | 	ssl.endpoint.identification.algorithm = https
kafka-ui                         | 	ssl.engine.factory.class = null
kafka-ui                         | 	ssl.key.password = null
kafka-ui                         | 	ssl.keymanager.algorithm = SunX509
kafka-ui                         | 	ssl.keystore.certificate.chain = null
kafka-ui                         | 	ssl.keystore.key = null
kafka-ui                         | 	ssl.keystore.location = null
kafka-ui                         | 	ssl.keystore.password = null
kafka-ui                         | 	ssl.keystore.type = JKS
kafka-ui                         | 	ssl.protocol = TLSv1.3
kafka-ui                         | 	ssl.provider = null
kafka-ui                         | 	ssl.secure.random.implementation = null
kafka-ui                         | 	ssl.trustmanager.algorithm = PKIX
kafka-ui                         | 	ssl.truststore.certificates = null
kafka-ui                         | 	ssl.truststore.location = null
kafka-ui                         | 	ssl.truststore.password = null
kafka-ui                         | 	ssl.truststore.type = JKS
kafka-ui                         | 
kafka-ui                         | 
kafka-ui                         | [30m2023-08-03 11:57:31,206[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka1:29092 from bootstrap.servers as DNS resolution failed for kafka1
kafka-ui                         | [30m2023-08-03 11:57:31,207[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
kafka-ui                         | java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
kafka-ui                         | 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
kafka-ui                         | 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
kafka-ui                         | 	at reactor.core.publisher.Operators.error(Operators.java:198)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
kafka-ui                         | 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
kafka-ui                         | 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
kafka-ui                         | 	at reactor.core.publisher.Operators.complete(Operators.java:137)
kafka-ui                         | 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
kafka-ui                         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
kafka-ui                         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
kafka-ui                         | 	at java.base/java.lang.Thread.run(Thread.java:833)
kafka-ui                         | Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
kafka-ui                         | 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
kafka-ui                         | 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
kafka-ui                         | 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
kafka-ui                         | 	... 16 common frames omitted
kafka-ui                         | Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
kafka-ui                         | 	... 22 common frames omitted
kafka-ui                         | [30m2023-08-03 11:57:31,209[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
kafka-ui                         | [30m2023-08-03 11:57:56,199[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
kafka-ui                         | [30m2023-08-03 11:57:56,202[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
kafka-ui                         | 	bootstrap.servers = [kafka1:29092]
kafka-ui                         | 	client.dns.lookup = use_all_dns_ips
kafka-ui                         | 	client.id = kafka-ui-admin-1691063876-5
kafka-ui                         | 	connections.max.idle.ms = 300000
kafka-ui                         | 	default.api.timeout.ms = 60000
kafka-ui                         | 	metadata.max.age.ms = 300000
kafka-ui                         | 	metric.reporters = []
kafka-ui                         | 	metrics.num.samples = 2
kafka-ui                         | 	metrics.recording.level = INFO
kafka-ui                         | 	metrics.sample.window.ms = 30000
kafka-ui                         | 	receive.buffer.bytes = 65536
kafka-ui                         | 	reconnect.backoff.max.ms = 1000
kafka-ui                         | 	reconnect.backoff.ms = 50
kafka-ui                         | 	request.timeout.ms = 30000
kafka-ui                         | 	retries = 2147483647
kafka-ui                         | 	retry.backoff.ms = 100
kafka-ui                         | 	sasl.client.callback.handler.class = null
kafka-ui                         | 	sasl.jaas.config = null
kafka-ui                         | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-ui                         | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-ui                         | 	sasl.kerberos.service.name = null
kafka-ui                         | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-ui                         | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-ui                         | 	sasl.login.callback.handler.class = null
kafka-ui                         | 	sasl.login.class = null
kafka-ui                         | 	sasl.login.connect.timeout.ms = null
kafka-ui                         | 	sasl.login.read.timeout.ms = null
kafka-ui                         | 	sasl.login.refresh.buffer.seconds = 300
kafka-ui                         | 	sasl.login.refresh.min.period.seconds = 60
kafka-ui                         | 	sasl.login.refresh.window.factor = 0.8
kafka-ui                         | 	sasl.login.refresh.window.jitter = 0.05
kafka-ui                         | 	sasl.login.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.login.retry.backoff.ms = 100
kafka-ui                         | 	sasl.mechanism = GSSAPI
kafka-ui                         | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-ui                         | 	sasl.oauthbearer.expected.audience = null
kafka-ui                         | 	sasl.oauthbearer.expected.issuer = null
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-ui                         | 	sasl.oauthbearer.scope.claim.name = scope
kafka-ui                         | 	sasl.oauthbearer.sub.claim.name = sub
kafka-ui                         | 	sasl.oauthbearer.token.endpoint.url = null
kafka-ui                         | 	security.protocol = PLAINTEXT
kafka-ui                         | 	security.providers = null
kafka-ui                         | 	send.buffer.bytes = 131072
kafka-ui                         | 	socket.connection.setup.timeout.max.ms = 30000
kafka-ui                         | 	socket.connection.setup.timeout.ms = 10000
kafka-ui                         | 	ssl.cipher.suites = null
kafka-ui                         | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-ui                         | 	ssl.endpoint.identification.algorithm = https
kafka-ui                         | 	ssl.engine.factory.class = null
kafka-ui                         | 	ssl.key.password = null
kafka-ui                         | 	ssl.keymanager.algorithm = SunX509
kafka-ui                         | 	ssl.keystore.certificate.chain = null
kafka-ui                         | 	ssl.keystore.key = null
kafka-ui                         | 	ssl.keystore.location = null
kafka-ui                         | 	ssl.keystore.password = null
kafka-ui                         | 	ssl.keystore.type = JKS
kafka-ui                         | 	ssl.protocol = TLSv1.3
kafka-ui                         | 	ssl.provider = null
kafka-ui                         | 	ssl.secure.random.implementation = null
kafka-ui                         | 	ssl.trustmanager.algorithm = PKIX
kafka-ui                         | 	ssl.truststore.certificates = null
kafka-ui                         | 	ssl.truststore.location = null
kafka-ui                         | 	ssl.truststore.password = null
kafka-ui                         | 	ssl.truststore.type = JKS
kafka-ui                         | 
kafka-ui                         | 
kafka-ui                         | [30m2023-08-03 11:58:01,210[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka1:29092 from bootstrap.servers as DNS resolution failed for kafka1
kafka-ui                         | [30m2023-08-03 11:58:01,211[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
kafka-ui                         | java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
kafka-ui                         | 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
kafka-ui                         | 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
kafka-ui                         | 	at reactor.core.publisher.Operators.error(Operators.java:198)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
kafka-ui                         | 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
kafka-ui                         | 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
kafka-ui                         | 	at reactor.core.publisher.Operators.complete(Operators.java:137)
kafka-ui                         | 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
kafka-ui                         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
kafka-ui                         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
kafka-ui                         | 	at java.base/java.lang.Thread.run(Thread.java:833)
kafka-ui                         | Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
kafka-ui                         | 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
kafka-ui                         | 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
kafka-ui                         | 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
kafka-ui                         | 	... 16 common frames omitted
kafka-ui                         | Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
kafka-ui                         | 	... 22 common frames omitted
kafka-ui                         | [30m2023-08-03 11:58:01,213[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
kafka-ui                         | [30m2023-08-03 11:58:26,199[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
kafka-ui                         | [30m2023-08-03 11:58:26,202[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
kafka-ui                         | 	bootstrap.servers = [kafka1:29092]
kafka-ui                         | 	client.dns.lookup = use_all_dns_ips
kafka-ui                         | 	client.id = kafka-ui-admin-1691063906-6
kafka-ui                         | 	connections.max.idle.ms = 300000
kafka-ui                         | 	default.api.timeout.ms = 60000
kafka-ui                         | 	metadata.max.age.ms = 300000
kafka-ui                         | 	metric.reporters = []
kafka-ui                         | 	metrics.num.samples = 2
kafka-ui                         | 	metrics.recording.level = INFO
kafka-ui                         | 	metrics.sample.window.ms = 30000
kafka-ui                         | 	receive.buffer.bytes = 65536
kafka-ui                         | 	reconnect.backoff.max.ms = 1000
kafka-ui                         | 	reconnect.backoff.ms = 50
kafka-ui                         | 	request.timeout.ms = 30000
kafka-ui                         | 	retries = 2147483647
kafka-ui                         | 	retry.backoff.ms = 100
kafka-ui                         | 	sasl.client.callback.handler.class = null
kafka-ui                         | 	sasl.jaas.config = null
kafka-ui                         | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-ui                         | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-ui                         | 	sasl.kerberos.service.name = null
kafka-ui                         | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-ui                         | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-ui                         | 	sasl.login.callback.handler.class = null
kafka-ui                         | 	sasl.login.class = null
kafka-ui                         | 	sasl.login.connect.timeout.ms = null
kafka-ui                         | 	sasl.login.read.timeout.ms = null
kafka-ui                         | 	sasl.login.refresh.buffer.seconds = 300
kafka-ui                         | 	sasl.login.refresh.min.period.seconds = 60
kafka-ui                         | 	sasl.login.refresh.window.factor = 0.8
kafka-ui                         | 	sasl.login.refresh.window.jitter = 0.05
kafka-ui                         | 	sasl.login.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.login.retry.backoff.ms = 100
kafka-ui                         | 	sasl.mechanism = GSSAPI
kafka-ui                         | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-ui                         | 	sasl.oauthbearer.expected.audience = null
kafka-ui                         | 	sasl.oauthbearer.expected.issuer = null
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-ui                         | 	sasl.oauthbearer.scope.claim.name = scope
kafka-ui                         | 	sasl.oauthbearer.sub.claim.name = sub
kafka-ui                         | 	sasl.oauthbearer.token.endpoint.url = null
kafka-ui                         | 	security.protocol = PLAINTEXT
kafka-ui                         | 	security.providers = null
kafka-ui                         | 	send.buffer.bytes = 131072
kafka-ui                         | 	socket.connection.setup.timeout.max.ms = 30000
kafka-ui                         | 	socket.connection.setup.timeout.ms = 10000
kafka-ui                         | 	ssl.cipher.suites = null
kafka-ui                         | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-ui                         | 	ssl.endpoint.identification.algorithm = https
kafka-ui                         | 	ssl.engine.factory.class = null
kafka-ui                         | 	ssl.key.password = null
kafka-ui                         | 	ssl.keymanager.algorithm = SunX509
kafka-ui                         | 	ssl.keystore.certificate.chain = null
kafka-ui                         | 	ssl.keystore.key = null
kafka-ui                         | 	ssl.keystore.location = null
kafka-ui                         | 	ssl.keystore.password = null
kafka-ui                         | 	ssl.keystore.type = JKS
kafka-ui                         | 	ssl.protocol = TLSv1.3
kafka-ui                         | 	ssl.provider = null
kafka-ui                         | 	ssl.secure.random.implementation = null
kafka-ui                         | 	ssl.trustmanager.algorithm = PKIX
kafka-ui                         | 	ssl.truststore.certificates = null
kafka-ui                         | 	ssl.truststore.location = null
kafka-ui                         | 	ssl.truststore.password = null
kafka-ui                         | 	ssl.truststore.type = JKS
kafka-ui                         | 
kafka-ui                         | 
kafka-ui                         | [30m2023-08-03 11:58:31,208[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka1:29092 from bootstrap.servers as DNS resolution failed for kafka1
kafka-ui                         | [30m2023-08-03 11:58:31,210[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
kafka-ui                         | java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
kafka-ui                         | 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
kafka-ui                         | 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
kafka-ui                         | 	at reactor.core.publisher.Operators.error(Operators.java:198)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
kafka-ui                         | 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
kafka-ui                         | 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
kafka-ui                         | 	at reactor.core.publisher.Operators.complete(Operators.java:137)
kafka-ui                         | 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
kafka-ui                         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
kafka-ui                         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
kafka-ui                         | 	at java.base/java.lang.Thread.run(Thread.java:833)
kafka-ui                         | Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
kafka-ui                         | 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
kafka-ui                         | 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
kafka-ui                         | 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
kafka-ui                         | 	... 16 common frames omitted
kafka-ui                         | Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
kafka-ui                         | 	... 22 common frames omitted
kafka-ui                         | [30m2023-08-03 11:58:31,211[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
kafka-ui                         | [30m2023-08-03 11:58:56,198[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
kafka-ui                         | [30m2023-08-03 11:58:56,200[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
kafka-ui                         | 	bootstrap.servers = [kafka1:29092]
kafka-ui                         | 	client.dns.lookup = use_all_dns_ips
kafka-ui                         | 	client.id = kafka-ui-admin-1691063936-7
kafka-ui                         | 	connections.max.idle.ms = 300000
kafka-ui                         | 	default.api.timeout.ms = 60000
kafka-ui                         | 	metadata.max.age.ms = 300000
kafka-ui                         | 	metric.reporters = []
kafka-ui                         | 	metrics.num.samples = 2
kafka-ui                         | 	metrics.recording.level = INFO
kafka-ui                         | 	metrics.sample.window.ms = 30000
kafka-ui                         | 	receive.buffer.bytes = 65536
kafka-ui                         | 	reconnect.backoff.max.ms = 1000
kafka-ui                         | 	reconnect.backoff.ms = 50
kafka-ui                         | 	request.timeout.ms = 30000
kafka-ui                         | 	retries = 2147483647
kafka-ui                         | 	retry.backoff.ms = 100
kafka-ui                         | 	sasl.client.callback.handler.class = null
kafka-ui                         | 	sasl.jaas.config = null
kafka-ui                         | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-ui                         | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-ui                         | 	sasl.kerberos.service.name = null
kafka-ui                         | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-ui                         | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-ui                         | 	sasl.login.callback.handler.class = null
kafka-ui                         | 	sasl.login.class = null
kafka-ui                         | 	sasl.login.connect.timeout.ms = null
kafka-ui                         | 	sasl.login.read.timeout.ms = null
kafka-ui                         | 	sasl.login.refresh.buffer.seconds = 300
kafka-ui                         | 	sasl.login.refresh.min.period.seconds = 60
kafka-ui                         | 	sasl.login.refresh.window.factor = 0.8
kafka-ui                         | 	sasl.login.refresh.window.jitter = 0.05
kafka-ui                         | 	sasl.login.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.login.retry.backoff.ms = 100
kafka-ui                         | 	sasl.mechanism = GSSAPI
kafka-ui                         | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-ui                         | 	sasl.oauthbearer.expected.audience = null
kafka-ui                         | 	sasl.oauthbearer.expected.issuer = null
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-ui                         | 	sasl.oauthbearer.scope.claim.name = scope
kafka-ui                         | 	sasl.oauthbearer.sub.claim.name = sub
kafka-ui                         | 	sasl.oauthbearer.token.endpoint.url = null
kafka-ui                         | 	security.protocol = PLAINTEXT
kafka-ui                         | 	security.providers = null
kafka-ui                         | 	send.buffer.bytes = 131072
kafka-ui                         | 	socket.connection.setup.timeout.max.ms = 30000
kafka-ui                         | 	socket.connection.setup.timeout.ms = 10000
kafka-ui                         | 	ssl.cipher.suites = null
kafka-ui                         | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-ui                         | 	ssl.endpoint.identification.algorithm = https
kafka-ui                         | 	ssl.engine.factory.class = null
kafka-ui                         | 	ssl.key.password = null
kafka-ui                         | 	ssl.keymanager.algorithm = SunX509
kafka-ui                         | 	ssl.keystore.certificate.chain = null
kafka-ui                         | 	ssl.keystore.key = null
kafka-ui                         | 	ssl.keystore.location = null
kafka-ui                         | 	ssl.keystore.password = null
kafka-ui                         | 	ssl.keystore.type = JKS
kafka-ui                         | 	ssl.protocol = TLSv1.3
kafka-ui                         | 	ssl.provider = null
kafka-ui                         | 	ssl.secure.random.implementation = null
kafka-ui                         | 	ssl.trustmanager.algorithm = PKIX
kafka-ui                         | 	ssl.truststore.certificates = null
kafka-ui                         | 	ssl.truststore.location = null
kafka-ui                         | 	ssl.truststore.password = null
kafka-ui                         | 	ssl.truststore.type = JKS
kafka-ui                         | 
kafka-ui                         | 
kafka-ui                         | [30m2023-08-03 11:59:01,205[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka1:29092 from bootstrap.servers as DNS resolution failed for kafka1
kafka-ui                         | [30m2023-08-03 11:59:01,207[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
kafka-ui                         | java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
kafka-ui                         | 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
kafka-ui                         | 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
kafka-ui                         | 	at reactor.core.publisher.Operators.error(Operators.java:198)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
kafka-ui                         | 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
kafka-ui                         | 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
kafka-ui                         | 	at reactor.core.publisher.Operators.complete(Operators.java:137)
kafka-ui                         | 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
kafka-ui                         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
kafka-ui                         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
kafka-ui                         | 	at java.base/java.lang.Thread.run(Thread.java:833)
kafka-ui                         | Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
kafka-ui                         | 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
kafka-ui                         | 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
kafka-ui                         | 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
kafka-ui                         | 	... 16 common frames omitted
kafka-ui                         | Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
kafka-ui                         | 	... 22 common frames omitted
kafka-ui                         | [30m2023-08-03 11:59:01,210[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
kafka-ui                         | [30m2023-08-03 11:59:26,198[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
kafka-ui                         | [30m2023-08-03 11:59:26,200[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
kafka-ui                         | 	bootstrap.servers = [kafka1:29092]
kafka-ui                         | 	client.dns.lookup = use_all_dns_ips
kafka-ui                         | 	client.id = kafka-ui-admin-1691063966-8
kafka-ui                         | 	connections.max.idle.ms = 300000
kafka-ui                         | 	default.api.timeout.ms = 60000
kafka-ui                         | 	metadata.max.age.ms = 300000
kafka-ui                         | 	metric.reporters = []
kafka-ui                         | 	metrics.num.samples = 2
kafka-ui                         | 	metrics.recording.level = INFO
kafka-ui                         | 	metrics.sample.window.ms = 30000
kafka-ui                         | 	receive.buffer.bytes = 65536
kafka-ui                         | 	reconnect.backoff.max.ms = 1000
kafka-ui                         | 	reconnect.backoff.ms = 50
kafka-ui                         | 	request.timeout.ms = 30000
kafka-ui                         | 	retries = 2147483647
kafka-ui                         | 	retry.backoff.ms = 100
kafka-ui                         | 	sasl.client.callback.handler.class = null
kafka-ui                         | 	sasl.jaas.config = null
kafka-ui                         | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-ui                         | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-ui                         | 	sasl.kerberos.service.name = null
kafka-ui                         | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-ui                         | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-ui                         | 	sasl.login.callback.handler.class = null
kafka-ui                         | 	sasl.login.class = null
kafka-ui                         | 	sasl.login.connect.timeout.ms = null
kafka-ui                         | 	sasl.login.read.timeout.ms = null
kafka-ui                         | 	sasl.login.refresh.buffer.seconds = 300
kafka-ui                         | 	sasl.login.refresh.min.period.seconds = 60
kafka-ui                         | 	sasl.login.refresh.window.factor = 0.8
kafka-ui                         | 	sasl.login.refresh.window.jitter = 0.05
kafka-ui                         | 	sasl.login.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.login.retry.backoff.ms = 100
kafka-ui                         | 	sasl.mechanism = GSSAPI
kafka-ui                         | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-ui                         | 	sasl.oauthbearer.expected.audience = null
kafka-ui                         | 	sasl.oauthbearer.expected.issuer = null
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-ui                         | 	sasl.oauthbearer.scope.claim.name = scope
kafka-ui                         | 	sasl.oauthbearer.sub.claim.name = sub
kafka-ui                         | 	sasl.oauthbearer.token.endpoint.url = null
kafka-ui                         | 	security.protocol = PLAINTEXT
kafka-ui                         | 	security.providers = null
kafka-ui                         | 	send.buffer.bytes = 131072
kafka-ui                         | 	socket.connection.setup.timeout.max.ms = 30000
kafka-ui                         | 	socket.connection.setup.timeout.ms = 10000
kafka-ui                         | 	ssl.cipher.suites = null
kafka-ui                         | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-ui                         | 	ssl.endpoint.identification.algorithm = https
kafka-ui                         | 	ssl.engine.factory.class = null
kafka-ui                         | 	ssl.key.password = null
kafka-ui                         | 	ssl.keymanager.algorithm = SunX509
kafka-ui                         | 	ssl.keystore.certificate.chain = null
kafka-ui                         | 	ssl.keystore.key = null
kafka-ui                         | 	ssl.keystore.location = null
kafka-ui                         | 	ssl.keystore.password = null
kafka-ui                         | 	ssl.keystore.type = JKS
kafka-ui                         | 	ssl.protocol = TLSv1.3
kafka-ui                         | 	ssl.provider = null
kafka-ui                         | 	ssl.secure.random.implementation = null
kafka-ui                         | 	ssl.trustmanager.algorithm = PKIX
kafka-ui                         | 	ssl.truststore.certificates = null
kafka-ui                         | 	ssl.truststore.location = null
kafka-ui                         | 	ssl.truststore.password = null
kafka-ui                         | 	ssl.truststore.type = JKS
kafka-ui                         | 
kafka-ui                         | 
kafka-ui                         | [30m2023-08-03 11:59:31,202[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka1:29092 from bootstrap.servers as DNS resolution failed for kafka1
kafka-ui                         | [30m2023-08-03 11:59:31,203[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
kafka-ui                         | java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
kafka-ui                         | 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
kafka-ui                         | 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
kafka-ui                         | 	at reactor.core.publisher.Operators.error(Operators.java:198)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
kafka-ui                         | 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
kafka-ui                         | 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
kafka-ui                         | 	at reactor.core.publisher.Operators.complete(Operators.java:137)
kafka-ui                         | 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
kafka-ui                         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
kafka-ui                         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
kafka-ui                         | 	at java.base/java.lang.Thread.run(Thread.java:833)
kafka-ui                         | Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
kafka-ui                         | 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
kafka-ui                         | 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
kafka-ui                         | 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
kafka-ui                         | 	... 16 common frames omitted
kafka-ui                         | Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
kafka-ui                         | 	... 22 common frames omitted
kafka-ui                         | [30m2023-08-03 11:59:31,206[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
kafka-ui                         | [30m2023-08-03 11:59:56,198[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
kafka-ui                         | [30m2023-08-03 11:59:56,201[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
kafka-ui                         | 	bootstrap.servers = [kafka1:29092]
kafka-ui                         | 	client.dns.lookup = use_all_dns_ips
kafka-ui                         | 	client.id = kafka-ui-admin-1691063996-9
kafka-ui                         | 	connections.max.idle.ms = 300000
kafka-ui                         | 	default.api.timeout.ms = 60000
kafka-ui                         | 	metadata.max.age.ms = 300000
kafka-ui                         | 	metric.reporters = []
kafka-ui                         | 	metrics.num.samples = 2
kafka-ui                         | 	metrics.recording.level = INFO
kafka-ui                         | 	metrics.sample.window.ms = 30000
kafka-ui                         | 	receive.buffer.bytes = 65536
kafka-ui                         | 	reconnect.backoff.max.ms = 1000
kafka-ui                         | 	reconnect.backoff.ms = 50
kafka-ui                         | 	request.timeout.ms = 30000
kafka-ui                         | 	retries = 2147483647
kafka-ui                         | 	retry.backoff.ms = 100
kafka-ui                         | 	sasl.client.callback.handler.class = null
kafka-ui                         | 	sasl.jaas.config = null
kafka-ui                         | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-ui                         | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-ui                         | 	sasl.kerberos.service.name = null
kafka-ui                         | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-ui                         | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-ui                         | 	sasl.login.callback.handler.class = null
kafka-ui                         | 	sasl.login.class = null
kafka-ui                         | 	sasl.login.connect.timeout.ms = null
kafka-ui                         | 	sasl.login.read.timeout.ms = null
kafka-ui                         | 	sasl.login.refresh.buffer.seconds = 300
kafka-ui                         | 	sasl.login.refresh.min.period.seconds = 60
kafka-ui                         | 	sasl.login.refresh.window.factor = 0.8
kafka-ui                         | 	sasl.login.refresh.window.jitter = 0.05
kafka-ui                         | 	sasl.login.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.login.retry.backoff.ms = 100
kafka-ui                         | 	sasl.mechanism = GSSAPI
kafka-ui                         | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-ui                         | 	sasl.oauthbearer.expected.audience = null
kafka-ui                         | 	sasl.oauthbearer.expected.issuer = null
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-ui                         | 	sasl.oauthbearer.scope.claim.name = scope
kafka-ui                         | 	sasl.oauthbearer.sub.claim.name = sub
kafka-ui                         | 	sasl.oauthbearer.token.endpoint.url = null
kafka-ui                         | 	security.protocol = PLAINTEXT
kafka-ui                         | 	security.providers = null
kafka-ui                         | 	send.buffer.bytes = 131072
kafka-ui                         | 	socket.connection.setup.timeout.max.ms = 30000
kafka-ui                         | 	socket.connection.setup.timeout.ms = 10000
kafka-ui                         | 	ssl.cipher.suites = null
kafka-ui                         | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-ui                         | 	ssl.endpoint.identification.algorithm = https
kafka-ui                         | 	ssl.engine.factory.class = null
kafka-ui                         | 	ssl.key.password = null
kafka-ui                         | 	ssl.keymanager.algorithm = SunX509
kafka-ui                         | 	ssl.keystore.certificate.chain = null
kafka-ui                         | 	ssl.keystore.key = null
kafka-ui                         | 	ssl.keystore.location = null
kafka-ui                         | 	ssl.keystore.password = null
kafka-ui                         | 	ssl.keystore.type = JKS
kafka-ui                         | 	ssl.protocol = TLSv1.3
kafka-ui                         | 	ssl.provider = null
kafka-ui                         | 	ssl.secure.random.implementation = null
kafka-ui                         | 	ssl.trustmanager.algorithm = PKIX
kafka-ui                         | 	ssl.truststore.certificates = null
kafka-ui                         | 	ssl.truststore.location = null
kafka-ui                         | 	ssl.truststore.password = null
kafka-ui                         | 	ssl.truststore.type = JKS
kafka-ui                         | 
kafka-ui                         | 
kafka-ui                         | [30m2023-08-03 12:00:01,207[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka1:29092 from bootstrap.servers as DNS resolution failed for kafka1
kafka-ui                         | [30m2023-08-03 12:00:01,208[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
kafka-ui                         | java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
kafka-ui                         | 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
kafka-ui                         | 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
kafka-ui                         | 	at reactor.core.publisher.Operators.error(Operators.java:198)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
kafka-ui                         | 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
kafka-ui                         | 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
kafka-ui                         | 	at reactor.core.publisher.Operators.complete(Operators.java:137)
kafka-ui                         | 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
kafka-ui                         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
kafka-ui                         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
kafka-ui                         | 	at java.base/java.lang.Thread.run(Thread.java:833)
kafka-ui                         | Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
kafka-ui                         | 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
kafka-ui                         | 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
kafka-ui                         | 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
kafka-ui                         | 	... 16 common frames omitted
kafka-ui                         | Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
kafka-ui                         | 	... 22 common frames omitted
kafka-ui                         | [30m2023-08-03 12:00:01,210[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
kafka-ui                         | [30m2023-08-03 12:00:26,198[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
kafka-ui                         | [30m2023-08-03 12:00:26,200[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
kafka-ui                         | 	bootstrap.servers = [kafka1:29092]
kafka-ui                         | 	client.dns.lookup = use_all_dns_ips
kafka-ui                         | 	client.id = kafka-ui-admin-1691064026-10
kafka-ui                         | 	connections.max.idle.ms = 300000
kafka-ui                         | 	default.api.timeout.ms = 60000
kafka-ui                         | 	metadata.max.age.ms = 300000
kafka-ui                         | 	metric.reporters = []
kafka-ui                         | 	metrics.num.samples = 2
kafka-ui                         | 	metrics.recording.level = INFO
kafka-ui                         | 	metrics.sample.window.ms = 30000
kafka-ui                         | 	receive.buffer.bytes = 65536
kafka-ui                         | 	reconnect.backoff.max.ms = 1000
kafka-ui                         | 	reconnect.backoff.ms = 50
kafka-ui                         | 	request.timeout.ms = 30000
kafka-ui                         | 	retries = 2147483647
kafka-ui                         | 	retry.backoff.ms = 100
kafka-ui                         | 	sasl.client.callback.handler.class = null
kafka-ui                         | 	sasl.jaas.config = null
kafka-ui                         | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-ui                         | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-ui                         | 	sasl.kerberos.service.name = null
kafka-ui                         | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-ui                         | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-ui                         | 	sasl.login.callback.handler.class = null
kafka-ui                         | 	sasl.login.class = null
kafka-ui                         | 	sasl.login.connect.timeout.ms = null
kafka-ui                         | 	sasl.login.read.timeout.ms = null
kafka-ui                         | 	sasl.login.refresh.buffer.seconds = 300
kafka-ui                         | 	sasl.login.refresh.min.period.seconds = 60
kafka-ui                         | 	sasl.login.refresh.window.factor = 0.8
kafka-ui                         | 	sasl.login.refresh.window.jitter = 0.05
kafka-ui                         | 	sasl.login.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.login.retry.backoff.ms = 100
kafka-ui                         | 	sasl.mechanism = GSSAPI
kafka-ui                         | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-ui                         | 	sasl.oauthbearer.expected.audience = null
kafka-ui                         | 	sasl.oauthbearer.expected.issuer = null
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-ui                         | 	sasl.oauthbearer.scope.claim.name = scope
kafka-ui                         | 	sasl.oauthbearer.sub.claim.name = sub
kafka-ui                         | 	sasl.oauthbearer.token.endpoint.url = null
kafka-ui                         | 	security.protocol = PLAINTEXT
kafka-ui                         | 	security.providers = null
kafka-ui                         | 	send.buffer.bytes = 131072
kafka-ui                         | 	socket.connection.setup.timeout.max.ms = 30000
kafka-ui                         | 	socket.connection.setup.timeout.ms = 10000
kafka-ui                         | 	ssl.cipher.suites = null
kafka-ui                         | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-ui                         | 	ssl.endpoint.identification.algorithm = https
kafka-ui                         | 	ssl.engine.factory.class = null
kafka-ui                         | 	ssl.key.password = null
kafka-ui                         | 	ssl.keymanager.algorithm = SunX509
kafka-ui                         | 	ssl.keystore.certificate.chain = null
kafka-ui                         | 	ssl.keystore.key = null
kafka-ui                         | 	ssl.keystore.location = null
kafka-ui                         | 	ssl.keystore.password = null
kafka-ui                         | 	ssl.keystore.type = JKS
kafka-ui                         | 	ssl.protocol = TLSv1.3
kafka-ui                         | 	ssl.provider = null
kafka-ui                         | 	ssl.secure.random.implementation = null
kafka-ui                         | 	ssl.trustmanager.algorithm = PKIX
kafka-ui                         | 	ssl.truststore.certificates = null
kafka-ui                         | 	ssl.truststore.location = null
kafka-ui                         | 	ssl.truststore.password = null
kafka-ui                         | 	ssl.truststore.type = JKS
kafka-ui                         | 
kafka-ui                         | 
kafka-ui                         | [30m2023-08-03 12:00:31,206[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka1:29092 from bootstrap.servers as DNS resolution failed for kafka1
kafka-ui                         | [30m2023-08-03 12:00:31,208[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
kafka-ui                         | java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
kafka-ui                         | 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
kafka-ui                         | 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
kafka-ui                         | 	at reactor.core.publisher.Operators.error(Operators.java:198)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
kafka-ui                         | 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
kafka-ui                         | 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
kafka-ui                         | 	at reactor.core.publisher.Operators.complete(Operators.java:137)
kafka-ui                         | 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
kafka-ui                         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
kafka-ui                         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
kafka-ui                         | 	at java.base/java.lang.Thread.run(Thread.java:833)
kafka-ui                         | Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
kafka-ui                         | 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
kafka-ui                         | 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
kafka-ui                         | 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
kafka-ui                         | 	... 16 common frames omitted
kafka-ui                         | Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
kafka-ui                         | 	... 22 common frames omitted
kafka-ui                         | [30m2023-08-03 12:00:31,214[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
kafka-ui                         | [30m2023-08-03 12:00:56,198[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
kafka-ui                         | [30m2023-08-03 12:00:56,200[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
kafka-ui                         | 	bootstrap.servers = [kafka1:29092]
kafka-ui                         | 	client.dns.lookup = use_all_dns_ips
kafka-ui                         | 	client.id = kafka-ui-admin-1691064056-11
kafka-ui                         | 	connections.max.idle.ms = 300000
kafka-ui                         | 	default.api.timeout.ms = 60000
kafka-ui                         | 	metadata.max.age.ms = 300000
kafka-ui                         | 	metric.reporters = []
kafka-ui                         | 	metrics.num.samples = 2
kafka-ui                         | 	metrics.recording.level = INFO
kafka-ui                         | 	metrics.sample.window.ms = 30000
kafka-ui                         | 	receive.buffer.bytes = 65536
kafka-ui                         | 	reconnect.backoff.max.ms = 1000
kafka-ui                         | 	reconnect.backoff.ms = 50
kafka-ui                         | 	request.timeout.ms = 30000
kafka-ui                         | 	retries = 2147483647
kafka-ui                         | 	retry.backoff.ms = 100
kafka-ui                         | 	sasl.client.callback.handler.class = null
kafka-ui                         | 	sasl.jaas.config = null
kafka-ui                         | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-ui                         | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-ui                         | 	sasl.kerberos.service.name = null
kafka-ui                         | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-ui                         | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-ui                         | 	sasl.login.callback.handler.class = null
kafka-ui                         | 	sasl.login.class = null
kafka-ui                         | 	sasl.login.connect.timeout.ms = null
kafka-ui                         | 	sasl.login.read.timeout.ms = null
kafka-ui                         | 	sasl.login.refresh.buffer.seconds = 300
kafka-ui                         | 	sasl.login.refresh.min.period.seconds = 60
kafka-ui                         | 	sasl.login.refresh.window.factor = 0.8
kafka-ui                         | 	sasl.login.refresh.window.jitter = 0.05
kafka-ui                         | 	sasl.login.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.login.retry.backoff.ms = 100
kafka-ui                         | 	sasl.mechanism = GSSAPI
kafka-ui                         | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-ui                         | 	sasl.oauthbearer.expected.audience = null
kafka-ui                         | 	sasl.oauthbearer.expected.issuer = null
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-ui                         | 	sasl.oauthbearer.scope.claim.name = scope
kafka-ui                         | 	sasl.oauthbearer.sub.claim.name = sub
kafka-ui                         | 	sasl.oauthbearer.token.endpoint.url = null
kafka-ui                         | 	security.protocol = PLAINTEXT
kafka-ui                         | 	security.providers = null
kafka-ui                         | 	send.buffer.bytes = 131072
kafka-ui                         | 	socket.connection.setup.timeout.max.ms = 30000
kafka-ui                         | 	socket.connection.setup.timeout.ms = 10000
kafka-ui                         | 	ssl.cipher.suites = null
kafka-ui                         | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-ui                         | 	ssl.endpoint.identification.algorithm = https
kafka-ui                         | 	ssl.engine.factory.class = null
kafka-ui                         | 	ssl.key.password = null
kafka-ui                         | 	ssl.keymanager.algorithm = SunX509
kafka-ui                         | 	ssl.keystore.certificate.chain = null
kafka-ui                         | 	ssl.keystore.key = null
kafka-ui                         | 	ssl.keystore.location = null
kafka-ui                         | 	ssl.keystore.password = null
kafka-ui                         | 	ssl.keystore.type = JKS
kafka-ui                         | 	ssl.protocol = TLSv1.3
kafka-ui                         | 	ssl.provider = null
kafka-ui                         | 	ssl.secure.random.implementation = null
kafka-ui                         | 	ssl.trustmanager.algorithm = PKIX
kafka-ui                         | 	ssl.truststore.certificates = null
kafka-ui                         | 	ssl.truststore.location = null
kafka-ui                         | 	ssl.truststore.password = null
kafka-ui                         | 	ssl.truststore.type = JKS
kafka-ui                         | 
kafka-ui                         | 
kafka-ui                         | [30m2023-08-03 12:01:01,206[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka1:29092 from bootstrap.servers as DNS resolution failed for kafka1
kafka-ui                         | [30m2023-08-03 12:01:01,207[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
kafka-ui                         | java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
kafka-ui                         | 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
kafka-ui                         | 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
kafka-ui                         | 	at reactor.core.publisher.Operators.error(Operators.java:198)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
kafka-ui                         | 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
kafka-ui                         | 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
kafka-ui                         | 	at reactor.core.publisher.Operators.complete(Operators.java:137)
kafka-ui                         | 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
kafka-ui                         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
kafka-ui                         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
kafka-ui                         | 	at java.base/java.lang.Thread.run(Thread.java:833)
kafka-ui                         | Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
kafka-ui                         | 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
kafka-ui                         | 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
kafka-ui                         | 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
kafka-ui                         | 	... 16 common frames omitted
kafka-ui                         | Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
kafka-ui                         | 	... 22 common frames omitted
kafka-ui                         | [30m2023-08-03 12:01:01,209[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
kafka-ui                         | [30m2023-08-03 12:01:26,198[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
kafka-ui                         | [30m2023-08-03 12:01:26,200[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
kafka-ui                         | 	bootstrap.servers = [kafka1:29092]
kafka-ui                         | 	client.dns.lookup = use_all_dns_ips
kafka-ui                         | 	client.id = kafka-ui-admin-1691064086-12
kafka-ui                         | 	connections.max.idle.ms = 300000
kafka-ui                         | 	default.api.timeout.ms = 60000
kafka-ui                         | 	metadata.max.age.ms = 300000
kafka-ui                         | 	metric.reporters = []
kafka-ui                         | 	metrics.num.samples = 2
kafka-ui                         | 	metrics.recording.level = INFO
kafka-ui                         | 	metrics.sample.window.ms = 30000
kafka-ui                         | 	receive.buffer.bytes = 65536
kafka-ui                         | 	reconnect.backoff.max.ms = 1000
kafka-ui                         | 	reconnect.backoff.ms = 50
kafka-ui                         | 	request.timeout.ms = 30000
kafka-ui                         | 	retries = 2147483647
kafka-ui                         | 	retry.backoff.ms = 100
kafka-ui                         | 	sasl.client.callback.handler.class = null
kafka-ui                         | 	sasl.jaas.config = null
kafka-ui                         | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-ui                         | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-ui                         | 	sasl.kerberos.service.name = null
kafka-ui                         | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-ui                         | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-ui                         | 	sasl.login.callback.handler.class = null
kafka-ui                         | 	sasl.login.class = null
kafka-ui                         | 	sasl.login.connect.timeout.ms = null
kafka-ui                         | 	sasl.login.read.timeout.ms = null
kafka-ui                         | 	sasl.login.refresh.buffer.seconds = 300
kafka-ui                         | 	sasl.login.refresh.min.period.seconds = 60
kafka-ui                         | 	sasl.login.refresh.window.factor = 0.8
kafka-ui                         | 	sasl.login.refresh.window.jitter = 0.05
kafka-ui                         | 	sasl.login.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.login.retry.backoff.ms = 100
kafka-ui                         | 	sasl.mechanism = GSSAPI
kafka-ui                         | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-ui                         | 	sasl.oauthbearer.expected.audience = null
kafka-ui                         | 	sasl.oauthbearer.expected.issuer = null
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-ui                         | 	sasl.oauthbearer.scope.claim.name = scope
kafka-ui                         | 	sasl.oauthbearer.sub.claim.name = sub
kafka-ui                         | 	sasl.oauthbearer.token.endpoint.url = null
kafka-ui                         | 	security.protocol = PLAINTEXT
kafka-ui                         | 	security.providers = null
kafka-ui                         | 	send.buffer.bytes = 131072
kafka-ui                         | 	socket.connection.setup.timeout.max.ms = 30000
kafka-ui                         | 	socket.connection.setup.timeout.ms = 10000
kafka-ui                         | 	ssl.cipher.suites = null
kafka-ui                         | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-ui                         | 	ssl.endpoint.identification.algorithm = https
kafka-ui                         | 	ssl.engine.factory.class = null
kafka-ui                         | 	ssl.key.password = null
kafka-ui                         | 	ssl.keymanager.algorithm = SunX509
kafka-ui                         | 	ssl.keystore.certificate.chain = null
kafka-ui                         | 	ssl.keystore.key = null
kafka-ui                         | 	ssl.keystore.location = null
kafka-ui                         | 	ssl.keystore.password = null
kafka-ui                         | 	ssl.keystore.type = JKS
kafka-ui                         | 	ssl.protocol = TLSv1.3
kafka-ui                         | 	ssl.provider = null
kafka-ui                         | 	ssl.secure.random.implementation = null
kafka-ui                         | 	ssl.trustmanager.algorithm = PKIX
kafka-ui                         | 	ssl.truststore.certificates = null
kafka-ui                         | 	ssl.truststore.location = null
kafka-ui                         | 	ssl.truststore.password = null
kafka-ui                         | 	ssl.truststore.type = JKS
kafka-ui                         | 
kafka-ui                         | 
kafka-ui                         | [30m2023-08-03 12:01:31,203[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka1:29092 from bootstrap.servers as DNS resolution failed for kafka1
kafka-ui                         | [30m2023-08-03 12:01:31,204[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
kafka-ui                         | java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
kafka-ui                         | 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
kafka-ui                         | 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
kafka-ui                         | 	at reactor.core.publisher.Operators.error(Operators.java:198)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
kafka-ui                         | 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
kafka-ui                         | 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
kafka-ui                         | 	at reactor.core.publisher.Operators.complete(Operators.java:137)
kafka-ui                         | 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
kafka-ui                         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
kafka-ui                         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
kafka-ui                         | 	at java.base/java.lang.Thread.run(Thread.java:833)
kafka-ui                         | Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
kafka-ui                         | 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
kafka-ui                         | 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
kafka-ui                         | 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
kafka-ui                         | 	... 16 common frames omitted
kafka-ui                         | Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
kafka-ui                         | 	... 22 common frames omitted
kafka-ui                         | [30m2023-08-03 12:01:31,205[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
kafka-ui                         | [30m2023-08-03 12:01:56,198[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
kafka-ui                         | [30m2023-08-03 12:01:56,200[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
kafka-ui                         | 	bootstrap.servers = [kafka1:29092]
kafka-ui                         | 	client.dns.lookup = use_all_dns_ips
kafka-ui                         | 	client.id = kafka-ui-admin-1691064116-13
kafka-ui                         | 	connections.max.idle.ms = 300000
kafka-ui                         | 	default.api.timeout.ms = 60000
kafka-ui                         | 	metadata.max.age.ms = 300000
kafka-ui                         | 	metric.reporters = []
kafka-ui                         | 	metrics.num.samples = 2
kafka-ui                         | 	metrics.recording.level = INFO
kafka-ui                         | 	metrics.sample.window.ms = 30000
kafka-ui                         | 	receive.buffer.bytes = 65536
kafka-ui                         | 	reconnect.backoff.max.ms = 1000
kafka-ui                         | 	reconnect.backoff.ms = 50
kafka-ui                         | 	request.timeout.ms = 30000
kafka-ui                         | 	retries = 2147483647
kafka-ui                         | 	retry.backoff.ms = 100
kafka-ui                         | 	sasl.client.callback.handler.class = null
kafka-ui                         | 	sasl.jaas.config = null
kafka-ui                         | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-ui                         | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-ui                         | 	sasl.kerberos.service.name = null
kafka-ui                         | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-ui                         | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-ui                         | 	sasl.login.callback.handler.class = null
kafka-ui                         | 	sasl.login.class = null
kafka-ui                         | 	sasl.login.connect.timeout.ms = null
kafka-ui                         | 	sasl.login.read.timeout.ms = null
kafka-ui                         | 	sasl.login.refresh.buffer.seconds = 300
kafka-ui                         | 	sasl.login.refresh.min.period.seconds = 60
kafka-ui                         | 	sasl.login.refresh.window.factor = 0.8
kafka-ui                         | 	sasl.login.refresh.window.jitter = 0.05
kafka-ui                         | 	sasl.login.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.login.retry.backoff.ms = 100
kafka-ui                         | 	sasl.mechanism = GSSAPI
kafka-ui                         | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-ui                         | 	sasl.oauthbearer.expected.audience = null
kafka-ui                         | 	sasl.oauthbearer.expected.issuer = null
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-ui                         | 	sasl.oauthbearer.scope.claim.name = scope
kafka-ui                         | 	sasl.oauthbearer.sub.claim.name = sub
kafka-ui                         | 	sasl.oauthbearer.token.endpoint.url = null
kafka-ui                         | 	security.protocol = PLAINTEXT
kafka-ui                         | 	security.providers = null
kafka-ui                         | 	send.buffer.bytes = 131072
kafka-ui                         | 	socket.connection.setup.timeout.max.ms = 30000
kafka-ui                         | 	socket.connection.setup.timeout.ms = 10000
kafka-ui                         | 	ssl.cipher.suites = null
kafka-ui                         | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-ui                         | 	ssl.endpoint.identification.algorithm = https
kafka-ui                         | 	ssl.engine.factory.class = null
kafka-ui                         | 	ssl.key.password = null
kafka-ui                         | 	ssl.keymanager.algorithm = SunX509
kafka-ui                         | 	ssl.keystore.certificate.chain = null
kafka-ui                         | 	ssl.keystore.key = null
kafka-ui                         | 	ssl.keystore.location = null
kafka-ui                         | 	ssl.keystore.password = null
kafka-ui                         | 	ssl.keystore.type = JKS
kafka-ui                         | 	ssl.protocol = TLSv1.3
kafka-ui                         | 	ssl.provider = null
kafka-ui                         | 	ssl.secure.random.implementation = null
kafka-ui                         | 	ssl.trustmanager.algorithm = PKIX
kafka-ui                         | 	ssl.truststore.certificates = null
kafka-ui                         | 	ssl.truststore.location = null
kafka-ui                         | 	ssl.truststore.password = null
kafka-ui                         | 	ssl.truststore.type = JKS
kafka-ui                         | 
kafka-ui                         | 
kafka-ui                         | [30m2023-08-03 12:02:01,205[0;39m [31mWARN [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka1:29092 from bootstrap.servers as DNS resolution failed for kafka1
kafka-ui                         | [30m2023-08-03 12:02:01,206[0;39m [1;31mERROR[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
kafka-ui                         | java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
kafka-ui                         | 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
kafka-ui                         | 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
kafka-ui                         | 	at reactor.core.publisher.Operators.error(Operators.java:198)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
kafka-ui                         | 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
kafka-ui                         | 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
kafka-ui                         | 	at reactor.core.publisher.Operators.complete(Operators.java:137)
kafka-ui                         | 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
kafka-ui                         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
kafka-ui                         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
kafka-ui                         | 	at java.base/java.lang.Thread.run(Thread.java:833)
kafka-ui                         | Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
kafka-ui                         | 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
kafka-ui                         | 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
kafka-ui                         | 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
kafka-ui                         | 	... 16 common frames omitted
kafka-ui                         | Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
kafka-ui                         | 	... 22 common frames omitted
kafka-ui                         | [30m2023-08-03 12:02:01,209[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
kafka-ui                         | [30m2023-08-03 12:02:26,200[0;39m [39mDEBUG[0;39m [[34mparallel-3[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
kafka-ui                         | [30m2023-08-03 12:02:26,204[0;39m [34mINFO [0;39m [[34mparallel-3[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
kafka-ui                         | 	bootstrap.servers = [kafka1:29092]
kafka-ui                         | 	client.dns.lookup = use_all_dns_ips
kafka-ui                         | 	client.id = kafka-ui-admin-1691064146-14
kafka-ui                         | 	connections.max.idle.ms = 300000
kafka-ui                         | 	default.api.timeout.ms = 60000
kafka-ui                         | 	metadata.max.age.ms = 300000
kafka-ui                         | 	metric.reporters = []
kafka-ui                         | 	metrics.num.samples = 2
kafka-ui                         | 	metrics.recording.level = INFO
kafka-ui                         | 	metrics.sample.window.ms = 30000
kafka-ui                         | 	receive.buffer.bytes = 65536
kafka-ui                         | 	reconnect.backoff.max.ms = 1000
kafka-ui                         | 	reconnect.backoff.ms = 50
kafka-ui                         | 	request.timeout.ms = 30000
kafka-ui                         | 	retries = 2147483647
kafka-ui                         | 	retry.backoff.ms = 100
kafka-ui                         | 	sasl.client.callback.handler.class = null
kafka-ui                         | 	sasl.jaas.config = null
kafka-ui                         | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-ui                         | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-ui                         | 	sasl.kerberos.service.name = null
kafka-ui                         | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-ui                         | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-ui                         | 	sasl.login.callback.handler.class = null
kafka-ui                         | 	sasl.login.class = null
kafka-ui                         | 	sasl.login.connect.timeout.ms = null
kafka-ui                         | 	sasl.login.read.timeout.ms = null
kafka-ui                         | 	sasl.login.refresh.buffer.seconds = 300
kafka-ui                         | 	sasl.login.refresh.min.period.seconds = 60
kafka-ui                         | 	sasl.login.refresh.window.factor = 0.8
kafka-ui                         | 	sasl.login.refresh.window.jitter = 0.05
kafka-ui                         | 	sasl.login.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.login.retry.backoff.ms = 100
kafka-ui                         | 	sasl.mechanism = GSSAPI
kafka-ui                         | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-ui                         | 	sasl.oauthbearer.expected.audience = null
kafka-ui                         | 	sasl.oauthbearer.expected.issuer = null
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-ui                         | 	sasl.oauthbearer.scope.claim.name = scope
kafka-ui                         | 	sasl.oauthbearer.sub.claim.name = sub
kafka-ui                         | 	sasl.oauthbearer.token.endpoint.url = null
kafka-ui                         | 	security.protocol = PLAINTEXT
kafka-ui                         | 	security.providers = null
kafka-ui                         | 	send.buffer.bytes = 131072
kafka-ui                         | 	socket.connection.setup.timeout.max.ms = 30000
kafka-ui                         | 	socket.connection.setup.timeout.ms = 10000
kafka-ui                         | 	ssl.cipher.suites = null
kafka-ui                         | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-ui                         | 	ssl.endpoint.identification.algorithm = https
kafka-ui                         | 	ssl.engine.factory.class = null
kafka-ui                         | 	ssl.key.password = null
kafka-ui                         | 	ssl.keymanager.algorithm = SunX509
kafka-ui                         | 	ssl.keystore.certificate.chain = null
kafka-ui                         | 	ssl.keystore.key = null
kafka-ui                         | 	ssl.keystore.location = null
kafka-ui                         | 	ssl.keystore.password = null
kafka-ui                         | 	ssl.keystore.type = JKS
kafka-ui                         | 	ssl.protocol = TLSv1.3
kafka-ui                         | 	ssl.provider = null
kafka-ui                         | 	ssl.secure.random.implementation = null
kafka-ui                         | 	ssl.trustmanager.algorithm = PKIX
kafka-ui                         | 	ssl.truststore.certificates = null
kafka-ui                         | 	ssl.truststore.location = null
kafka-ui                         | 	ssl.truststore.password = null
kafka-ui                         | 	ssl.truststore.type = JKS
kafka-ui                         | 
kafka-ui                         | 
kafka-ui                         | [30m2023-08-03 12:02:31,209[0;39m [31mWARN [0;39m [[34mparallel-3[0;39m] [33mo.a.k.c.ClientUtils[0;39m: Couldn't resolve server kafka1:29092 from bootstrap.servers as DNS resolution failed for kafka1
kafka-ui                         | [30m2023-08-03 12:02:31,210[0;39m [1;31mERROR[0;39m [[34mparallel-3[0;39m] [33mc.p.k.u.s.StatisticsService[0;39m: Failed to collect cluster local info
kafka-ui                         | java.lang.IllegalStateException: Error while creating AdminClient for Cluster local
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$5(AdminClientServiceImpl.java:56)
kafka-ui                         | 	at reactor.core.publisher.Mono.lambda$onErrorMap$28(Mono.java:3773)
kafka-ui                         | 	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)
kafka-ui                         | 	at reactor.core.publisher.Operators.error(Operators.java:198)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:135)
kafka-ui                         | 	at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4470)
kafka-ui                         | 	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:82)
kafka-ui                         | 	at reactor.core.publisher.Operators.complete(Operators.java:137)
kafka-ui                         | 	at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
kafka-ui                         | 	at reactor.core.publisher.Mono.subscribe(Mono.java:4485)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:427)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440)
kafka-ui                         | 	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84)
kafka-ui                         | 	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37)
kafka-ui                         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
kafka-ui                         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
kafka-ui                         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
kafka-ui                         | 	at java.base/java.lang.Thread.run(Thread.java:833)
kafka-ui                         | Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:553)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:485)
kafka-ui                         | 	at org.apache.kafka.clients.admin.Admin.create(Admin.java:134)
kafka-ui                         | 	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
kafka-ui                         | 	at com.provectus.kafka.ui.service.AdminClientServiceImpl.lambda$createAdminClient$2(AdminClientServiceImpl.java:53)
kafka-ui                         | 	at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:67)
kafka-ui                         | 	at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:127)
kafka-ui                         | 	... 16 common frames omitted
kafka-ui                         | Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
kafka-ui                         | 	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
kafka-ui                         | 	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:505)
kafka-ui                         | 	... 22 common frames omitted
kafka-ui                         | [30m2023-08-03 12:02:31,211[0;39m [39mDEBUG[0;39m [[34mparallel-3[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
kafka-ui                         | [30m2023-08-03 12:02:56,198[0;39m [39mDEBUG[0;39m [[34mparallel-3[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
kafka-ui                         | [30m2023-08-03 12:02:56,200[0;39m [34mINFO [0;39m [[34mparallel-3[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
kafka-ui                         | 	bootstrap.servers = [kafka1:29092]
kafka-ui                         | 	client.dns.lookup = use_all_dns_ips
kafka-ui                         | 	client.id = kafka-ui-admin-1691064176-15
kafka-ui                         | 	connections.max.idle.ms = 300000
kafka-ui                         | 	default.api.timeout.ms = 60000
kafka-ui                         | 	metadata.max.age.ms = 300000
kafka-ui                         | 	metric.reporters = []
kafka-ui                         | 	metrics.num.samples = 2
kafka-ui                         | 	metrics.recording.level = INFO
kafka-ui                         | 	metrics.sample.window.ms = 30000
kafka-ui                         | 	receive.buffer.bytes = 65536
kafka-ui                         | 	reconnect.backoff.max.ms = 1000
kafka-ui                         | 	reconnect.backoff.ms = 50
kafka-ui                         | 	request.timeout.ms = 30000
kafka-ui                         | 	retries = 2147483647
kafka-ui                         | 	retry.backoff.ms = 100
kafka-ui                         | 	sasl.client.callback.handler.class = null
kafka-ui                         | 	sasl.jaas.config = null
kafka-ui                         | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-ui                         | 	sasl.kerberos.min.time.before.relogin = 60000
kafka-ui                         | 	sasl.kerberos.service.name = null
kafka-ui                         | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka-ui                         | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-ui                         | 	sasl.login.callback.handler.class = null
kafka-ui                         | 	sasl.login.class = null
kafka-ui                         | 	sasl.login.connect.timeout.ms = null
kafka-ui                         | 	sasl.login.read.timeout.ms = null
kafka-ui                         | 	sasl.login.refresh.buffer.seconds = 300
kafka-ui                         | 	sasl.login.refresh.min.period.seconds = 60
kafka-ui                         | 	sasl.login.refresh.window.factor = 0.8
kafka-ui                         | 	sasl.login.refresh.window.jitter = 0.05
kafka-ui                         | 	sasl.login.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.login.retry.backoff.ms = 100
kafka-ui                         | 	sasl.mechanism = GSSAPI
kafka-ui                         | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka-ui                         | 	sasl.oauthbearer.expected.audience = null
kafka-ui                         | 	sasl.oauthbearer.expected.issuer = null
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-ui                         | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka-ui                         | 	sasl.oauthbearer.scope.claim.name = scope
kafka-ui                         | 	sasl.oauthbearer.sub.claim.name = sub
kafka-ui                         | 	sasl.oauthbearer.token.endpoint.url = null
kafka-ui                         | 	security.protocol = PLAINTEXT
kafka-ui                         | 	security.providers = null
kafka-ui                         | 	send.buffer.bytes = 131072
kafka-ui                         | 	socket.connection.setup.timeout.max.ms = 30000
kafka-ui                         | 	socket.connection.setup.timeout.ms = 10000
kafka-ui                         | 	ssl.cipher.suites = null
kafka-ui                         | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-ui                         | 	ssl.endpoint.identification.algorithm = https
kafka-ui                         | 	ssl.engine.factory.class = null
kafka-ui                         | 	ssl.key.password = null
kafka-ui                         | 	ssl.keymanager.algorithm = SunX509
kafka-ui                         | 	ssl.keystore.certificate.chain = null
kafka-ui                         | 	ssl.keystore.key = null
kafka-ui                         | 	ssl.keystore.location = null
kafka-ui                         | 	ssl.keystore.password = null
kafka-ui                         | 	ssl.keystore.type = JKS
kafka-ui                         | 	ssl.protocol = TLSv1.3
kafka-ui                         | 	ssl.provider = null
kafka-ui                         | 	ssl.secure.random.implementation = null
kafka-ui                         | 	ssl.trustmanager.algorithm = PKIX
kafka-ui                         | 	ssl.truststore.certificates = null
kafka-ui                         | 	ssl.truststore.location = null
kafka-ui                         | 	ssl.truststore.password = null
kafka-ui                         | 	ssl.truststore.type = JKS
kafka-ui                         | 
kafka-ui                         | 
Gracefully stopping... (press Ctrl+C again to force)
Aborting on container exit...
 Container kafka-ui  Stopping
 Container kafka_kraft-kafka-init-topics-1  Stopping
 Container kafka_kraft-kafka-init-topics-1  Stopped
 Container kafka-ui  Stopped
 Container schema-registry  Stopping
 Container schema-registry  Stopped
 Container kafka1  Stopping
 Container kafka1  Stopped
canceled
